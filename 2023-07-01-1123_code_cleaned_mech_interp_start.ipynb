{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, GPT2Model, GPT2Tokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pp\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "import elk \n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "from plotly_utils import imshow\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Experiments with T5 (UnifiedQA) model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "imdb_ds = load_dataset('imdb')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|██████████| 3/3 [00:00<00:00, 701.94it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 701.94it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def t5_experiments():\n",
    "    samples = [\n",
    "    f'''\n",
    "    {imdb_ds['train']['text'][:1]}\n",
    "    Did the reviewer find this movie good or bad? \n",
    "    bad\n",
    "    ''',\n",
    "    f'''\n",
    "    {imdb_ds['train']['text'][:1]}\n",
    "    Did the reviewer find this movie good or bad? \n",
    "    good\n",
    "    ''',\n",
    "    ]\n",
    "\n",
    "    model_name = \"allenai/unifiedqa-t5-base\" \n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    sample = imdb_ds['train']['text'][156:157]\n",
    "    input_ids = tokenizer.encode(f'''\n",
    "        {sample}\n",
    "        Did the reviewer find this movie good or bad?''', return_tensors=\"pt\")\n",
    "    # TODO: broken forward call.\n",
    "    # output = model.forward(input_ids=input_ids, output_hidden_states=True)\n",
    "    # pp(f\"{output['decoder_hidden_states'][0].shape=}\")\n",
    "    # l11cp = elk.training.Reporter.load(f'./data/allenai/unifiedqa-t5-base/imdb/quirky-neumann/reporters/layer_11.pt', map_location=device)\n",
    "    # pp((output['decoder_hidden_states'][0][0,-1] == output['decoder_hidden_states'][0][1,-1]).float().mean())\n",
    "    # pp(l11cp(output['decoder_hidden_states'][0][0,-1]))\n",
    "    # pp(l11cp(output['decoder_hidden_states'][0][1,-1]))\n",
    "\n",
    "#t5_experiments()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Experiments with GPT2-XL\n",
    "# Loading. Warning. This takes +16GB of RAM.\n",
    "gpt2_xl: HookedTransformer = HookedTransformer.from_pretrained(\"gpt2-xl\")\n",
    "gpt2_xl.eval()\n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "pp(gpt2_xl)\n",
    "\n",
    "#gpt2_xl : GPT2Model = GPT2Model.from_pretrained('gpt2-xl')\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "#gpt2_xl.eval()\n",
    "#pp(gpt2_xl)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n",
      "HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-47): 48 x TransformerBlock(\n",
      "      (ln1): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNormPre(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Experimenting with TruthfulQA dataset."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 730.84it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []\n",
    "while correct_statements or incorrect_statements:\n",
    "    x : torch.Tensor = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1)\n",
    "            inx = tokens.shape[1] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        x.squeeze_(0)\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  3363,\n",
      "           11, 49696,   457,  9038,   373, 11897,    11,  3584,   339,  6699,\n",
      "          465, 14934,    13, 16973,   262,  9329,   527,   456, 25201,  1683,\n",
      "        16019,    30,  1400,    11,   262,  9329,   527,   456, 25201,   318,\n",
      "          257,  5863,  4692,  1339,    13]),\n",
      " [(23, 0), (45, 1)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "with torch.inference_mode():\n",
    "    output, cache = gpt2_xl.run_with_cache(dataset[0][0])\n",
    "\n",
    "#with torch.inference_mode():\n",
    "#    output = gpt2_xl.forward(dataset[0][0], output_hidden_states=True)\n",
    "#    cache = output['hidden_states']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pp(f'{len(cache)=}')\n",
    "pp(f'{cache[48].shape=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'len(cache)=868'\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 3\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=116'>117</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=117'>118</a>\u001b[0m pp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(cache)\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=118'>119</a>\u001b[0m pp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcache[\u001b[39m48\u001b[39;49m]\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py:77\u001b[0m, in \u001b[0;36mActivationCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_dict[utils\u001b[39m.\u001b[39mget_act_name(key)]\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=75'>76</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=76'>77</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m key[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=77'>78</a>\u001b[0m         \u001b[39mif\u001b[39;00m key[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=78'>79</a>\u001b[0m             \u001b[39m# Supports negative indexing on the layer dimension\u001b[39;00m\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=79'>80</a>\u001b[0m             key \u001b[39m=\u001b[39m (key[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mn_layers \u001b[39m+\u001b[39m key[\u001b[39m1\u001b[39m], \u001b[39m*\u001b[39mkey[\u001b[39m2\u001b[39m:])\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pp(f'{cache=}')\n",
    "pp(f'{cache[48].shape=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(\"cache=ActivationCache with keys ['hook_embed', 'hook_pos_embed', \"\n",
      " \"'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', \"\n",
      " \"'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', \"\n",
      " \"'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', \"\n",
      " \"'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', \"\n",
      " \"'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', \"\n",
      " \"'blocks.0.hook_mlp_in', 'blocks.0.ln2.hook_scale', \"\n",
      " \"'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', \"\n",
      " \"'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', \"\n",
      " \"'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', \"\n",
      " \"'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', \"\n",
      " \"'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', \"\n",
      " \"'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', \"\n",
      " \"'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', \"\n",
      " \"'blocks.1.hook_mlp_in', 'blocks.1.ln2.hook_scale', \"\n",
      " \"'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', \"\n",
      " \"'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', \"\n",
      " \"'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', \"\n",
      " \"'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', \"\n",
      " \"'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', \"\n",
      " \"'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', \"\n",
      " \"'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', \"\n",
      " \"'blocks.2.hook_mlp_in', 'blocks.2.ln2.hook_scale', \"\n",
      " \"'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', \"\n",
      " \"'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', \"\n",
      " \"'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', \"\n",
      " \"'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', \"\n",
      " \"'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', \"\n",
      " \"'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', \"\n",
      " \"'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', \"\n",
      " \"'blocks.3.hook_mlp_in', 'blocks.3.ln2.hook_scale', \"\n",
      " \"'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', \"\n",
      " \"'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', \"\n",
      " \"'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', \"\n",
      " \"'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', \"\n",
      " \"'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', \"\n",
      " \"'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', \"\n",
      " \"'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', \"\n",
      " \"'blocks.4.hook_mlp_in', 'blocks.4.ln2.hook_scale', \"\n",
      " \"'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', \"\n",
      " \"'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', \"\n",
      " \"'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', \"\n",
      " \"'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', \"\n",
      " \"'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', \"\n",
      " \"'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', \"\n",
      " \"'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', \"\n",
      " \"'blocks.5.hook_mlp_in', 'blocks.5.ln2.hook_scale', \"\n",
      " \"'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', \"\n",
      " \"'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', \"\n",
      " \"'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', \"\n",
      " \"'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', \"\n",
      " \"'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', \"\n",
      " \"'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', \"\n",
      " \"'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', \"\n",
      " \"'blocks.6.hook_mlp_in', 'blocks.6.ln2.hook_scale', \"\n",
      " \"'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', \"\n",
      " \"'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', \"\n",
      " \"'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', \"\n",
      " \"'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', \"\n",
      " \"'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', \"\n",
      " \"'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', \"\n",
      " \"'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', \"\n",
      " \"'blocks.7.hook_mlp_in', 'blocks.7.ln2.hook_scale', \"\n",
      " \"'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', \"\n",
      " \"'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', \"\n",
      " \"'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', \"\n",
      " \"'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', \"\n",
      " \"'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', \"\n",
      " \"'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', \"\n",
      " \"'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', \"\n",
      " \"'blocks.8.hook_mlp_in', 'blocks.8.ln2.hook_scale', \"\n",
      " \"'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', \"\n",
      " \"'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', \"\n",
      " \"'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', \"\n",
      " \"'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', \"\n",
      " \"'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', \"\n",
      " \"'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', \"\n",
      " \"'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', \"\n",
      " \"'blocks.9.hook_mlp_in', 'blocks.9.ln2.hook_scale', \"\n",
      " \"'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', \"\n",
      " \"'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', \"\n",
      " \"'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', \"\n",
      " \"'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', \"\n",
      " \"'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', \"\n",
      " \"'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', \"\n",
      " \"'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', \"\n",
      " \"'blocks.10.hook_resid_mid', 'blocks.10.hook_mlp_in', \"\n",
      " \"'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', \"\n",
      " \"'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', \"\n",
      " \"'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', \"\n",
      " \"'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', \"\n",
      " \"'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', \"\n",
      " \"'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', \"\n",
      " \"'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', \"\n",
      " \"'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', \"\n",
      " \"'blocks.11.hook_resid_mid', 'blocks.11.hook_mlp_in', \"\n",
      " \"'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', \"\n",
      " \"'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', \"\n",
      " \"'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', \"\n",
      " \"'blocks.12.hook_resid_pre', 'blocks.12.ln1.hook_scale', \"\n",
      " \"'blocks.12.ln1.hook_normalized', 'blocks.12.attn.hook_q', \"\n",
      " \"'blocks.12.attn.hook_k', 'blocks.12.attn.hook_v', \"\n",
      " \"'blocks.12.attn.hook_attn_scores', 'blocks.12.attn.hook_pattern', \"\n",
      " \"'blocks.12.attn.hook_z', 'blocks.12.hook_attn_out', \"\n",
      " \"'blocks.12.hook_resid_mid', 'blocks.12.hook_mlp_in', \"\n",
      " \"'blocks.12.ln2.hook_scale', 'blocks.12.ln2.hook_normalized', \"\n",
      " \"'blocks.12.mlp.hook_pre', 'blocks.12.mlp.hook_post', \"\n",
      " \"'blocks.12.hook_mlp_out', 'blocks.12.hook_resid_post', \"\n",
      " \"'blocks.13.hook_resid_pre', 'blocks.13.ln1.hook_scale', \"\n",
      " \"'blocks.13.ln1.hook_normalized', 'blocks.13.attn.hook_q', \"\n",
      " \"'blocks.13.attn.hook_k', 'blocks.13.attn.hook_v', \"\n",
      " \"'blocks.13.attn.hook_attn_scores', 'blocks.13.attn.hook_pattern', \"\n",
      " \"'blocks.13.attn.hook_z', 'blocks.13.hook_attn_out', \"\n",
      " \"'blocks.13.hook_resid_mid', 'blocks.13.hook_mlp_in', \"\n",
      " \"'blocks.13.ln2.hook_scale', 'blocks.13.ln2.hook_normalized', \"\n",
      " \"'blocks.13.mlp.hook_pre', 'blocks.13.mlp.hook_post', \"\n",
      " \"'blocks.13.hook_mlp_out', 'blocks.13.hook_resid_post', \"\n",
      " \"'blocks.14.hook_resid_pre', 'blocks.14.ln1.hook_scale', \"\n",
      " \"'blocks.14.ln1.hook_normalized', 'blocks.14.attn.hook_q', \"\n",
      " \"'blocks.14.attn.hook_k', 'blocks.14.attn.hook_v', \"\n",
      " \"'blocks.14.attn.hook_attn_scores', 'blocks.14.attn.hook_pattern', \"\n",
      " \"'blocks.14.attn.hook_z', 'blocks.14.hook_attn_out', \"\n",
      " \"'blocks.14.hook_resid_mid', 'blocks.14.hook_mlp_in', \"\n",
      " \"'blocks.14.ln2.hook_scale', 'blocks.14.ln2.hook_normalized', \"\n",
      " \"'blocks.14.mlp.hook_pre', 'blocks.14.mlp.hook_post', \"\n",
      " \"'blocks.14.hook_mlp_out', 'blocks.14.hook_resid_post', \"\n",
      " \"'blocks.15.hook_resid_pre', 'blocks.15.ln1.hook_scale', \"\n",
      " \"'blocks.15.ln1.hook_normalized', 'blocks.15.attn.hook_q', \"\n",
      " \"'blocks.15.attn.hook_k', 'blocks.15.attn.hook_v', \"\n",
      " \"'blocks.15.attn.hook_attn_scores', 'blocks.15.attn.hook_pattern', \"\n",
      " \"'blocks.15.attn.hook_z', 'blocks.15.hook_attn_out', \"\n",
      " \"'blocks.15.hook_resid_mid', 'blocks.15.hook_mlp_in', \"\n",
      " \"'blocks.15.ln2.hook_scale', 'blocks.15.ln2.hook_normalized', \"\n",
      " \"'blocks.15.mlp.hook_pre', 'blocks.15.mlp.hook_post', \"\n",
      " \"'blocks.15.hook_mlp_out', 'blocks.15.hook_resid_post', \"\n",
      " \"'blocks.16.hook_resid_pre', 'blocks.16.ln1.hook_scale', \"\n",
      " \"'blocks.16.ln1.hook_normalized', 'blocks.16.attn.hook_q', \"\n",
      " \"'blocks.16.attn.hook_k', 'blocks.16.attn.hook_v', \"\n",
      " \"'blocks.16.attn.hook_attn_scores', 'blocks.16.attn.hook_pattern', \"\n",
      " \"'blocks.16.attn.hook_z', 'blocks.16.hook_attn_out', \"\n",
      " \"'blocks.16.hook_resid_mid', 'blocks.16.hook_mlp_in', \"\n",
      " \"'blocks.16.ln2.hook_scale', 'blocks.16.ln2.hook_normalized', \"\n",
      " \"'blocks.16.mlp.hook_pre', 'blocks.16.mlp.hook_post', \"\n",
      " \"'blocks.16.hook_mlp_out', 'blocks.16.hook_resid_post', \"\n",
      " \"'blocks.17.hook_resid_pre', 'blocks.17.ln1.hook_scale', \"\n",
      " \"'blocks.17.ln1.hook_normalized', 'blocks.17.attn.hook_q', \"\n",
      " \"'blocks.17.attn.hook_k', 'blocks.17.attn.hook_v', \"\n",
      " \"'blocks.17.attn.hook_attn_scores', 'blocks.17.attn.hook_pattern', \"\n",
      " \"'blocks.17.attn.hook_z', 'blocks.17.hook_attn_out', \"\n",
      " \"'blocks.17.hook_resid_mid', 'blocks.17.hook_mlp_in', \"\n",
      " \"'blocks.17.ln2.hook_scale', 'blocks.17.ln2.hook_normalized', \"\n",
      " \"'blocks.17.mlp.hook_pre', 'blocks.17.mlp.hook_post', \"\n",
      " \"'blocks.17.hook_mlp_out', 'blocks.17.hook_resid_post', \"\n",
      " \"'blocks.18.hook_resid_pre', 'blocks.18.ln1.hook_scale', \"\n",
      " \"'blocks.18.ln1.hook_normalized', 'blocks.18.attn.hook_q', \"\n",
      " \"'blocks.18.attn.hook_k', 'blocks.18.attn.hook_v', \"\n",
      " \"'blocks.18.attn.hook_attn_scores', 'blocks.18.attn.hook_pattern', \"\n",
      " \"'blocks.18.attn.hook_z', 'blocks.18.hook_attn_out', \"\n",
      " \"'blocks.18.hook_resid_mid', 'blocks.18.hook_mlp_in', \"\n",
      " \"'blocks.18.ln2.hook_scale', 'blocks.18.ln2.hook_normalized', \"\n",
      " \"'blocks.18.mlp.hook_pre', 'blocks.18.mlp.hook_post', \"\n",
      " \"'blocks.18.hook_mlp_out', 'blocks.18.hook_resid_post', \"\n",
      " \"'blocks.19.hook_resid_pre', 'blocks.19.ln1.hook_scale', \"\n",
      " \"'blocks.19.ln1.hook_normalized', 'blocks.19.attn.hook_q', \"\n",
      " \"'blocks.19.attn.hook_k', 'blocks.19.attn.hook_v', \"\n",
      " \"'blocks.19.attn.hook_attn_scores', 'blocks.19.attn.hook_pattern', \"\n",
      " \"'blocks.19.attn.hook_z', 'blocks.19.hook_attn_out', \"\n",
      " \"'blocks.19.hook_resid_mid', 'blocks.19.hook_mlp_in', \"\n",
      " \"'blocks.19.ln2.hook_scale', 'blocks.19.ln2.hook_normalized', \"\n",
      " \"'blocks.19.mlp.hook_pre', 'blocks.19.mlp.hook_post', \"\n",
      " \"'blocks.19.hook_mlp_out', 'blocks.19.hook_resid_post', \"\n",
      " \"'blocks.20.hook_resid_pre', 'blocks.20.ln1.hook_scale', \"\n",
      " \"'blocks.20.ln1.hook_normalized', 'blocks.20.attn.hook_q', \"\n",
      " \"'blocks.20.attn.hook_k', 'blocks.20.attn.hook_v', \"\n",
      " \"'blocks.20.attn.hook_attn_scores', 'blocks.20.attn.hook_pattern', \"\n",
      " \"'blocks.20.attn.hook_z', 'blocks.20.hook_attn_out', \"\n",
      " \"'blocks.20.hook_resid_mid', 'blocks.20.hook_mlp_in', \"\n",
      " \"'blocks.20.ln2.hook_scale', 'blocks.20.ln2.hook_normalized', \"\n",
      " \"'blocks.20.mlp.hook_pre', 'blocks.20.mlp.hook_post', \"\n",
      " \"'blocks.20.hook_mlp_out', 'blocks.20.hook_resid_post', \"\n",
      " \"'blocks.21.hook_resid_pre', 'blocks.21.ln1.hook_scale', \"\n",
      " \"'blocks.21.ln1.hook_normalized', 'blocks.21.attn.hook_q', \"\n",
      " \"'blocks.21.attn.hook_k', 'blocks.21.attn.hook_v', \"\n",
      " \"'blocks.21.attn.hook_attn_scores', 'blocks.21.attn.hook_pattern', \"\n",
      " \"'blocks.21.attn.hook_z', 'blocks.21.hook_attn_out', \"\n",
      " \"'blocks.21.hook_resid_mid', 'blocks.21.hook_mlp_in', \"\n",
      " \"'blocks.21.ln2.hook_scale', 'blocks.21.ln2.hook_normalized', \"\n",
      " \"'blocks.21.mlp.hook_pre', 'blocks.21.mlp.hook_post', \"\n",
      " \"'blocks.21.hook_mlp_out', 'blocks.21.hook_resid_post', \"\n",
      " \"'blocks.22.hook_resid_pre', 'blocks.22.ln1.hook_scale', \"\n",
      " \"'blocks.22.ln1.hook_normalized', 'blocks.22.attn.hook_q', \"\n",
      " \"'blocks.22.attn.hook_k', 'blocks.22.attn.hook_v', \"\n",
      " \"'blocks.22.attn.hook_attn_scores', 'blocks.22.attn.hook_pattern', \"\n",
      " \"'blocks.22.attn.hook_z', 'blocks.22.hook_attn_out', \"\n",
      " \"'blocks.22.hook_resid_mid', 'blocks.22.hook_mlp_in', \"\n",
      " \"'blocks.22.ln2.hook_scale', 'blocks.22.ln2.hook_normalized', \"\n",
      " \"'blocks.22.mlp.hook_pre', 'blocks.22.mlp.hook_post', \"\n",
      " \"'blocks.22.hook_mlp_out', 'blocks.22.hook_resid_post', \"\n",
      " \"'blocks.23.hook_resid_pre', 'blocks.23.ln1.hook_scale', \"\n",
      " \"'blocks.23.ln1.hook_normalized', 'blocks.23.attn.hook_q', \"\n",
      " \"'blocks.23.attn.hook_k', 'blocks.23.attn.hook_v', \"\n",
      " \"'blocks.23.attn.hook_attn_scores', 'blocks.23.attn.hook_pattern', \"\n",
      " \"'blocks.23.attn.hook_z', 'blocks.23.hook_attn_out', \"\n",
      " \"'blocks.23.hook_resid_mid', 'blocks.23.hook_mlp_in', \"\n",
      " \"'blocks.23.ln2.hook_scale', 'blocks.23.ln2.hook_normalized', \"\n",
      " \"'blocks.23.mlp.hook_pre', 'blocks.23.mlp.hook_post', \"\n",
      " \"'blocks.23.hook_mlp_out', 'blocks.23.hook_resid_post', \"\n",
      " \"'blocks.24.hook_resid_pre', 'blocks.24.ln1.hook_scale', \"\n",
      " \"'blocks.24.ln1.hook_normalized', 'blocks.24.attn.hook_q', \"\n",
      " \"'blocks.24.attn.hook_k', 'blocks.24.attn.hook_v', \"\n",
      " \"'blocks.24.attn.hook_attn_scores', 'blocks.24.attn.hook_pattern', \"\n",
      " \"'blocks.24.attn.hook_z', 'blocks.24.hook_attn_out', \"\n",
      " \"'blocks.24.hook_resid_mid', 'blocks.24.hook_mlp_in', \"\n",
      " \"'blocks.24.ln2.hook_scale', 'blocks.24.ln2.hook_normalized', \"\n",
      " \"'blocks.24.mlp.hook_pre', 'blocks.24.mlp.hook_post', \"\n",
      " \"'blocks.24.hook_mlp_out', 'blocks.24.hook_resid_post', \"\n",
      " \"'blocks.25.hook_resid_pre', 'blocks.25.ln1.hook_scale', \"\n",
      " \"'blocks.25.ln1.hook_normalized', 'blocks.25.attn.hook_q', \"\n",
      " \"'blocks.25.attn.hook_k', 'blocks.25.attn.hook_v', \"\n",
      " \"'blocks.25.attn.hook_attn_scores', 'blocks.25.attn.hook_pattern', \"\n",
      " \"'blocks.25.attn.hook_z', 'blocks.25.hook_attn_out', \"\n",
      " \"'blocks.25.hook_resid_mid', 'blocks.25.hook_mlp_in', \"\n",
      " \"'blocks.25.ln2.hook_scale', 'blocks.25.ln2.hook_normalized', \"\n",
      " \"'blocks.25.mlp.hook_pre', 'blocks.25.mlp.hook_post', \"\n",
      " \"'blocks.25.hook_mlp_out', 'blocks.25.hook_resid_post', \"\n",
      " \"'blocks.26.hook_resid_pre', 'blocks.26.ln1.hook_scale', \"\n",
      " \"'blocks.26.ln1.hook_normalized', 'blocks.26.attn.hook_q', \"\n",
      " \"'blocks.26.attn.hook_k', 'blocks.26.attn.hook_v', \"\n",
      " \"'blocks.26.attn.hook_attn_scores', 'blocks.26.attn.hook_pattern', \"\n",
      " \"'blocks.26.attn.hook_z', 'blocks.26.hook_attn_out', \"\n",
      " \"'blocks.26.hook_resid_mid', 'blocks.26.hook_mlp_in', \"\n",
      " \"'blocks.26.ln2.hook_scale', 'blocks.26.ln2.hook_normalized', \"\n",
      " \"'blocks.26.mlp.hook_pre', 'blocks.26.mlp.hook_post', \"\n",
      " \"'blocks.26.hook_mlp_out', 'blocks.26.hook_resid_post', \"\n",
      " \"'blocks.27.hook_resid_pre', 'blocks.27.ln1.hook_scale', \"\n",
      " \"'blocks.27.ln1.hook_normalized', 'blocks.27.attn.hook_q', \"\n",
      " \"'blocks.27.attn.hook_k', 'blocks.27.attn.hook_v', \"\n",
      " \"'blocks.27.attn.hook_attn_scores', 'blocks.27.attn.hook_pattern', \"\n",
      " \"'blocks.27.attn.hook_z', 'blocks.27.hook_attn_out', \"\n",
      " \"'blocks.27.hook_resid_mid', 'blocks.27.hook_mlp_in', \"\n",
      " \"'blocks.27.ln2.hook_scale', 'blocks.27.ln2.hook_normalized', \"\n",
      " \"'blocks.27.mlp.hook_pre', 'blocks.27.mlp.hook_post', \"\n",
      " \"'blocks.27.hook_mlp_out', 'blocks.27.hook_resid_post', \"\n",
      " \"'blocks.28.hook_resid_pre', 'blocks.28.ln1.hook_scale', \"\n",
      " \"'blocks.28.ln1.hook_normalized', 'blocks.28.attn.hook_q', \"\n",
      " \"'blocks.28.attn.hook_k', 'blocks.28.attn.hook_v', \"\n",
      " \"'blocks.28.attn.hook_attn_scores', 'blocks.28.attn.hook_pattern', \"\n",
      " \"'blocks.28.attn.hook_z', 'blocks.28.hook_attn_out', \"\n",
      " \"'blocks.28.hook_resid_mid', 'blocks.28.hook_mlp_in', \"\n",
      " \"'blocks.28.ln2.hook_scale', 'blocks.28.ln2.hook_normalized', \"\n",
      " \"'blocks.28.mlp.hook_pre', 'blocks.28.mlp.hook_post', \"\n",
      " \"'blocks.28.hook_mlp_out', 'blocks.28.hook_resid_post', \"\n",
      " \"'blocks.29.hook_resid_pre', 'blocks.29.ln1.hook_scale', \"\n",
      " \"'blocks.29.ln1.hook_normalized', 'blocks.29.attn.hook_q', \"\n",
      " \"'blocks.29.attn.hook_k', 'blocks.29.attn.hook_v', \"\n",
      " \"'blocks.29.attn.hook_attn_scores', 'blocks.29.attn.hook_pattern', \"\n",
      " \"'blocks.29.attn.hook_z', 'blocks.29.hook_attn_out', \"\n",
      " \"'blocks.29.hook_resid_mid', 'blocks.29.hook_mlp_in', \"\n",
      " \"'blocks.29.ln2.hook_scale', 'blocks.29.ln2.hook_normalized', \"\n",
      " \"'blocks.29.mlp.hook_pre', 'blocks.29.mlp.hook_post', \"\n",
      " \"'blocks.29.hook_mlp_out', 'blocks.29.hook_resid_post', \"\n",
      " \"'blocks.30.hook_resid_pre', 'blocks.30.ln1.hook_scale', \"\n",
      " \"'blocks.30.ln1.hook_normalized', 'blocks.30.attn.hook_q', \"\n",
      " \"'blocks.30.attn.hook_k', 'blocks.30.attn.hook_v', \"\n",
      " \"'blocks.30.attn.hook_attn_scores', 'blocks.30.attn.hook_pattern', \"\n",
      " \"'blocks.30.attn.hook_z', 'blocks.30.hook_attn_out', \"\n",
      " \"'blocks.30.hook_resid_mid', 'blocks.30.hook_mlp_in', \"\n",
      " \"'blocks.30.ln2.hook_scale', 'blocks.30.ln2.hook_normalized', \"\n",
      " \"'blocks.30.mlp.hook_pre', 'blocks.30.mlp.hook_post', \"\n",
      " \"'blocks.30.hook_mlp_out', 'blocks.30.hook_resid_post', \"\n",
      " \"'blocks.31.hook_resid_pre', 'blocks.31.ln1.hook_scale', \"\n",
      " \"'blocks.31.ln1.hook_normalized', 'blocks.31.attn.hook_q', \"\n",
      " \"'blocks.31.attn.hook_k', 'blocks.31.attn.hook_v', \"\n",
      " \"'blocks.31.attn.hook_attn_scores', 'blocks.31.attn.hook_pattern', \"\n",
      " \"'blocks.31.attn.hook_z', 'blocks.31.hook_attn_out', \"\n",
      " \"'blocks.31.hook_resid_mid', 'blocks.31.hook_mlp_in', \"\n",
      " \"'blocks.31.ln2.hook_scale', 'blocks.31.ln2.hook_normalized', \"\n",
      " \"'blocks.31.mlp.hook_pre', 'blocks.31.mlp.hook_post', \"\n",
      " \"'blocks.31.hook_mlp_out', 'blocks.31.hook_resid_post', \"\n",
      " \"'blocks.32.hook_resid_pre', 'blocks.32.ln1.hook_scale', \"\n",
      " \"'blocks.32.ln1.hook_normalized', 'blocks.32.attn.hook_q', \"\n",
      " \"'blocks.32.attn.hook_k', 'blocks.32.attn.hook_v', \"\n",
      " \"'blocks.32.attn.hook_attn_scores', 'blocks.32.attn.hook_pattern', \"\n",
      " \"'blocks.32.attn.hook_z', 'blocks.32.hook_attn_out', \"\n",
      " \"'blocks.32.hook_resid_mid', 'blocks.32.hook_mlp_in', \"\n",
      " \"'blocks.32.ln2.hook_scale', 'blocks.32.ln2.hook_normalized', \"\n",
      " \"'blocks.32.mlp.hook_pre', 'blocks.32.mlp.hook_post', \"\n",
      " \"'blocks.32.hook_mlp_out', 'blocks.32.hook_resid_post', \"\n",
      " \"'blocks.33.hook_resid_pre', 'blocks.33.ln1.hook_scale', \"\n",
      " \"'blocks.33.ln1.hook_normalized', 'blocks.33.attn.hook_q', \"\n",
      " \"'blocks.33.attn.hook_k', 'blocks.33.attn.hook_v', \"\n",
      " \"'blocks.33.attn.hook_attn_scores', 'blocks.33.attn.hook_pattern', \"\n",
      " \"'blocks.33.attn.hook_z', 'blocks.33.hook_attn_out', \"\n",
      " \"'blocks.33.hook_resid_mid', 'blocks.33.hook_mlp_in', \"\n",
      " \"'blocks.33.ln2.hook_scale', 'blocks.33.ln2.hook_normalized', \"\n",
      " \"'blocks.33.mlp.hook_pre', 'blocks.33.mlp.hook_post', \"\n",
      " \"'blocks.33.hook_mlp_out', 'blocks.33.hook_resid_post', \"\n",
      " \"'blocks.34.hook_resid_pre', 'blocks.34.ln1.hook_scale', \"\n",
      " \"'blocks.34.ln1.hook_normalized', 'blocks.34.attn.hook_q', \"\n",
      " \"'blocks.34.attn.hook_k', 'blocks.34.attn.hook_v', \"\n",
      " \"'blocks.34.attn.hook_attn_scores', 'blocks.34.attn.hook_pattern', \"\n",
      " \"'blocks.34.attn.hook_z', 'blocks.34.hook_attn_out', \"\n",
      " \"'blocks.34.hook_resid_mid', 'blocks.34.hook_mlp_in', \"\n",
      " \"'blocks.34.ln2.hook_scale', 'blocks.34.ln2.hook_normalized', \"\n",
      " \"'blocks.34.mlp.hook_pre', 'blocks.34.mlp.hook_post', \"\n",
      " \"'blocks.34.hook_mlp_out', 'blocks.34.hook_resid_post', \"\n",
      " \"'blocks.35.hook_resid_pre', 'blocks.35.ln1.hook_scale', \"\n",
      " \"'blocks.35.ln1.hook_normalized', 'blocks.35.attn.hook_q', \"\n",
      " \"'blocks.35.attn.hook_k', 'blocks.35.attn.hook_v', \"\n",
      " \"'blocks.35.attn.hook_attn_scores', 'blocks.35.attn.hook_pattern', \"\n",
      " \"'blocks.35.attn.hook_z', 'blocks.35.hook_attn_out', \"\n",
      " \"'blocks.35.hook_resid_mid', 'blocks.35.hook_mlp_in', \"\n",
      " \"'blocks.35.ln2.hook_scale', 'blocks.35.ln2.hook_normalized', \"\n",
      " \"'blocks.35.mlp.hook_pre', 'blocks.35.mlp.hook_post', \"\n",
      " \"'blocks.35.hook_mlp_out', 'blocks.35.hook_resid_post', \"\n",
      " \"'blocks.36.hook_resid_pre', 'blocks.36.ln1.hook_scale', \"\n",
      " \"'blocks.36.ln1.hook_normalized', 'blocks.36.attn.hook_q', \"\n",
      " \"'blocks.36.attn.hook_k', 'blocks.36.attn.hook_v', \"\n",
      " \"'blocks.36.attn.hook_attn_scores', 'blocks.36.attn.hook_pattern', \"\n",
      " \"'blocks.36.attn.hook_z', 'blocks.36.hook_attn_out', \"\n",
      " \"'blocks.36.hook_resid_mid', 'blocks.36.hook_mlp_in', \"\n",
      " \"'blocks.36.ln2.hook_scale', 'blocks.36.ln2.hook_normalized', \"\n",
      " \"'blocks.36.mlp.hook_pre', 'blocks.36.mlp.hook_post', \"\n",
      " \"'blocks.36.hook_mlp_out', 'blocks.36.hook_resid_post', \"\n",
      " \"'blocks.37.hook_resid_pre', 'blocks.37.ln1.hook_scale', \"\n",
      " \"'blocks.37.ln1.hook_normalized', 'blocks.37.attn.hook_q', \"\n",
      " \"'blocks.37.attn.hook_k', 'blocks.37.attn.hook_v', \"\n",
      " \"'blocks.37.attn.hook_attn_scores', 'blocks.37.attn.hook_pattern', \"\n",
      " \"'blocks.37.attn.hook_z', 'blocks.37.hook_attn_out', \"\n",
      " \"'blocks.37.hook_resid_mid', 'blocks.37.hook_mlp_in', \"\n",
      " \"'blocks.37.ln2.hook_scale', 'blocks.37.ln2.hook_normalized', \"\n",
      " \"'blocks.37.mlp.hook_pre', 'blocks.37.mlp.hook_post', \"\n",
      " \"'blocks.37.hook_mlp_out', 'blocks.37.hook_resid_post', \"\n",
      " \"'blocks.38.hook_resid_pre', 'blocks.38.ln1.hook_scale', \"\n",
      " \"'blocks.38.ln1.hook_normalized', 'blocks.38.attn.hook_q', \"\n",
      " \"'blocks.38.attn.hook_k', 'blocks.38.attn.hook_v', \"\n",
      " \"'blocks.38.attn.hook_attn_scores', 'blocks.38.attn.hook_pattern', \"\n",
      " \"'blocks.38.attn.hook_z', 'blocks.38.hook_attn_out', \"\n",
      " \"'blocks.38.hook_resid_mid', 'blocks.38.hook_mlp_in', \"\n",
      " \"'blocks.38.ln2.hook_scale', 'blocks.38.ln2.hook_normalized', \"\n",
      " \"'blocks.38.mlp.hook_pre', 'blocks.38.mlp.hook_post', \"\n",
      " \"'blocks.38.hook_mlp_out', 'blocks.38.hook_resid_post', \"\n",
      " \"'blocks.39.hook_resid_pre', 'blocks.39.ln1.hook_scale', \"\n",
      " \"'blocks.39.ln1.hook_normalized', 'blocks.39.attn.hook_q', \"\n",
      " \"'blocks.39.attn.hook_k', 'blocks.39.attn.hook_v', \"\n",
      " \"'blocks.39.attn.hook_attn_scores', 'blocks.39.attn.hook_pattern', \"\n",
      " \"'blocks.39.attn.hook_z', 'blocks.39.hook_attn_out', \"\n",
      " \"'blocks.39.hook_resid_mid', 'blocks.39.hook_mlp_in', \"\n",
      " \"'blocks.39.ln2.hook_scale', 'blocks.39.ln2.hook_normalized', \"\n",
      " \"'blocks.39.mlp.hook_pre', 'blocks.39.mlp.hook_post', \"\n",
      " \"'blocks.39.hook_mlp_out', 'blocks.39.hook_resid_post', \"\n",
      " \"'blocks.40.hook_resid_pre', 'blocks.40.ln1.hook_scale', \"\n",
      " \"'blocks.40.ln1.hook_normalized', 'blocks.40.attn.hook_q', \"\n",
      " \"'blocks.40.attn.hook_k', 'blocks.40.attn.hook_v', \"\n",
      " \"'blocks.40.attn.hook_attn_scores', 'blocks.40.attn.hook_pattern', \"\n",
      " \"'blocks.40.attn.hook_z', 'blocks.40.hook_attn_out', \"\n",
      " \"'blocks.40.hook_resid_mid', 'blocks.40.hook_mlp_in', \"\n",
      " \"'blocks.40.ln2.hook_scale', 'blocks.40.ln2.hook_normalized', \"\n",
      " \"'blocks.40.mlp.hook_pre', 'blocks.40.mlp.hook_post', \"\n",
      " \"'blocks.40.hook_mlp_out', 'blocks.40.hook_resid_post', \"\n",
      " \"'blocks.41.hook_resid_pre', 'blocks.41.ln1.hook_scale', \"\n",
      " \"'blocks.41.ln1.hook_normalized', 'blocks.41.attn.hook_q', \"\n",
      " \"'blocks.41.attn.hook_k', 'blocks.41.attn.hook_v', \"\n",
      " \"'blocks.41.attn.hook_attn_scores', 'blocks.41.attn.hook_pattern', \"\n",
      " \"'blocks.41.attn.hook_z', 'blocks.41.hook_attn_out', \"\n",
      " \"'blocks.41.hook_resid_mid', 'blocks.41.hook_mlp_in', \"\n",
      " \"'blocks.41.ln2.hook_scale', 'blocks.41.ln2.hook_normalized', \"\n",
      " \"'blocks.41.mlp.hook_pre', 'blocks.41.mlp.hook_post', \"\n",
      " \"'blocks.41.hook_mlp_out', 'blocks.41.hook_resid_post', \"\n",
      " \"'blocks.42.hook_resid_pre', 'blocks.42.ln1.hook_scale', \"\n",
      " \"'blocks.42.ln1.hook_normalized', 'blocks.42.attn.hook_q', \"\n",
      " \"'blocks.42.attn.hook_k', 'blocks.42.attn.hook_v', \"\n",
      " \"'blocks.42.attn.hook_attn_scores', 'blocks.42.attn.hook_pattern', \"\n",
      " \"'blocks.42.attn.hook_z', 'blocks.42.hook_attn_out', \"\n",
      " \"'blocks.42.hook_resid_mid', 'blocks.42.hook_mlp_in', \"\n",
      " \"'blocks.42.ln2.hook_scale', 'blocks.42.ln2.hook_normalized', \"\n",
      " \"'blocks.42.mlp.hook_pre', 'blocks.42.mlp.hook_post', \"\n",
      " \"'blocks.42.hook_mlp_out', 'blocks.42.hook_resid_post', \"\n",
      " \"'blocks.43.hook_resid_pre', 'blocks.43.ln1.hook_scale', \"\n",
      " \"'blocks.43.ln1.hook_normalized', 'blocks.43.attn.hook_q', \"\n",
      " \"'blocks.43.attn.hook_k', 'blocks.43.attn.hook_v', \"\n",
      " \"'blocks.43.attn.hook_attn_scores', 'blocks.43.attn.hook_pattern', \"\n",
      " \"'blocks.43.attn.hook_z', 'blocks.43.hook_attn_out', \"\n",
      " \"'blocks.43.hook_resid_mid', 'blocks.43.hook_mlp_in', \"\n",
      " \"'blocks.43.ln2.hook_scale', 'blocks.43.ln2.hook_normalized', \"\n",
      " \"'blocks.43.mlp.hook_pre', 'blocks.43.mlp.hook_post', \"\n",
      " \"'blocks.43.hook_mlp_out', 'blocks.43.hook_resid_post', \"\n",
      " \"'blocks.44.hook_resid_pre', 'blocks.44.ln1.hook_scale', \"\n",
      " \"'blocks.44.ln1.hook_normalized', 'blocks.44.attn.hook_q', \"\n",
      " \"'blocks.44.attn.hook_k', 'blocks.44.attn.hook_v', \"\n",
      " \"'blocks.44.attn.hook_attn_scores', 'blocks.44.attn.hook_pattern', \"\n",
      " \"'blocks.44.attn.hook_z', 'blocks.44.hook_attn_out', \"\n",
      " \"'blocks.44.hook_resid_mid', 'blocks.44.hook_mlp_in', \"\n",
      " \"'blocks.44.ln2.hook_scale', 'blocks.44.ln2.hook_normalized', \"\n",
      " \"'blocks.44.mlp.hook_pre', 'blocks.44.mlp.hook_post', \"\n",
      " \"'blocks.44.hook_mlp_out', 'blocks.44.hook_resid_post', \"\n",
      " \"'blocks.45.hook_resid_pre', 'blocks.45.ln1.hook_scale', \"\n",
      " \"'blocks.45.ln1.hook_normalized', 'blocks.45.attn.hook_q', \"\n",
      " \"'blocks.45.attn.hook_k', 'blocks.45.attn.hook_v', \"\n",
      " \"'blocks.45.attn.hook_attn_scores', 'blocks.45.attn.hook_pattern', \"\n",
      " \"'blocks.45.attn.hook_z', 'blocks.45.hook_attn_out', \"\n",
      " \"'blocks.45.hook_resid_mid', 'blocks.45.hook_mlp_in', \"\n",
      " \"'blocks.45.ln2.hook_scale', 'blocks.45.ln2.hook_normalized', \"\n",
      " \"'blocks.45.mlp.hook_pre', 'blocks.45.mlp.hook_post', \"\n",
      " \"'blocks.45.hook_mlp_out', 'blocks.45.hook_resid_post', \"\n",
      " \"'blocks.46.hook_resid_pre', 'blocks.46.ln1.hook_scale', \"\n",
      " \"'blocks.46.ln1.hook_normalized', 'blocks.46.attn.hook_q', \"\n",
      " \"'blocks.46.attn.hook_k', 'blocks.46.attn.hook_v', \"\n",
      " \"'blocks.46.attn.hook_attn_scores', 'blocks.46.attn.hook_pattern', \"\n",
      " \"'blocks.46.attn.hook_z', 'blocks.46.hook_attn_out', \"\n",
      " \"'blocks.46.hook_resid_mid', 'blocks.46.hook_mlp_in', \"\n",
      " \"'blocks.46.ln2.hook_scale', 'blocks.46.ln2.hook_normalized', \"\n",
      " \"'blocks.46.mlp.hook_pre', 'blocks.46.mlp.hook_post', \"\n",
      " \"'blocks.46.hook_mlp_out', 'blocks.46.hook_resid_post', \"\n",
      " \"'blocks.47.hook_resid_pre', 'blocks.47.ln1.hook_scale', \"\n",
      " \"'blocks.47.ln1.hook_normalized', 'blocks.47.attn.hook_q', \"\n",
      " \"'blocks.47.attn.hook_k', 'blocks.47.attn.hook_v', \"\n",
      " \"'blocks.47.attn.hook_attn_scores', 'blocks.47.attn.hook_pattern', \"\n",
      " \"'blocks.47.attn.hook_z', 'blocks.47.hook_attn_out', \"\n",
      " \"'blocks.47.hook_resid_mid', 'blocks.47.hook_mlp_in', \"\n",
      " \"'blocks.47.ln2.hook_scale', 'blocks.47.ln2.hook_normalized', \"\n",
      " \"'blocks.47.mlp.hook_pre', 'blocks.47.mlp.hook_post', \"\n",
      " \"'blocks.47.hook_mlp_out', 'blocks.47.hook_resid_post', \"\n",
      " \"'ln_final.hook_scale', 'ln_final.hook_normalized']\")\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 3\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=116'>117</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=117'>118</a>\u001b[0m pp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcache\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=118'>119</a>\u001b[0m pp(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcache[\u001b[39m48\u001b[39;49m]\u001b[39m.\u001b[39mshape\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py:77\u001b[0m, in \u001b[0;36mActivationCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=74'>75</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_dict[utils\u001b[39m.\u001b[39mget_act_name(key)]\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=75'>76</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=76'>77</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(key) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m key[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=77'>78</a>\u001b[0m         \u001b[39mif\u001b[39;00m key[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=78'>79</a>\u001b[0m             \u001b[39m# Supports negative indexing on the layer dimension\u001b[39;00m\n\u001b[1;32m     <a href='file:///root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/transformer_lens/ActivationCache.py?line=79'>80</a>\u001b[0m             key \u001b[39m=\u001b[39m (key[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mn_layers \u001b[39m+\u001b[39m key[\u001b[39m1\u001b[39m], \u001b[39m*\u001b[39mkey[\u001b[39m2\u001b[39m:])\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/imdb/festive-elion/reporters/layer_47.pt', map_location=device)\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/dbpedia_14/reporters/layer_47.pt', map_location=device)\n",
    "reporter.eval()\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#reporter = elk.training.Reporter.load(f'./data/gpt2-xl/imdb/festive-elion/reporters/layer_47.pt', map_location=device)\n",
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/dbpedia_14/reporters/layer_47.pt', map_location=device)\n",
    "reporter.eval()\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))[0].sigmoid()\n",
    "pp(res.shape)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(0.3684, device='cuda:0')\n",
      "45 1\n",
      "tensor(0.2966, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/ag_news/reporters/layer_47.pt', map_location=device)\n",
    "reporter.eval()\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))[0].sigmoid()\n",
    "pp(res.shape)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(0.4922, device='cuda:0')\n",
      "45 1\n",
      "tensor(0.4468, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "reporter = torch.load(f'./data/gpt2-xl/dbpedia_14/lr_models/layer_47.pt', map_location=device)[0]\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier(\n",
      "  (linear): Linear(in_features=1600, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/ag_news/reporters/layer_47.pt', map_location=device)\n",
    "reporter.eval()\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "reporter = torch.load(f'./data/gpt2-xl/dbpedia_14/lr_models/layer_47.pt', map_location=device)\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Classifier(\n",
      "  (linear): Linear(in_features=1600, out_features=1, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))\n",
    "    res = res[0]\n",
    "pp(res.shape)\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 3\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=150'>151</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=151'>152</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=152'>153</a>\u001b[0m     res \u001b[39m=\u001b[39m reporter(cache[\u001b[39m'\u001b[39;49m\u001b[39mmlp_out\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m47\u001b[39;49m][\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39msigmoid()\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=153'>154</a>\u001b[0m     \u001b[39m#res = reporter(cache[47].to(device))\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=154'>155</a>\u001b[0m     res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "reporter = torch.load(f'./data/gpt2-xl/dbpedia_14/lr_models/layer_47.pt', map_location=device)[0]\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classifier(\n",
      "  (linear): Linear(in_features=1600, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))\n",
    "    res = res[0]\n",
    "pp(res.shape)\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([])\n",
      "tensor(1., device='cuda:0')\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 22 is out of bounds for dimension 0 with size 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 11\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=158'>159</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=159'>160</a>\u001b[0m     \u001b[39mprint\u001b[39m(inx, label)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=160'>161</a>\u001b[0m     pp(res[inx\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 22 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))\n",
    "pp(res.shape)\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "tensor([1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
      "        0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 1., 0., 1., 1., 0., 0.], device='cuda:0')\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(1., device='cuda:0')\n",
      "45 1\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0])\n",
    "    #res = reporter(cache[47].to(device))\n",
    "pp(res.shape)\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "tensor([  9000.0908,  27037.9785, -11566.8740,  20659.0957,   7137.8345,\n",
      "         -1503.4360,   6340.8901,  -3719.1475,  -2780.1113,   2178.4526,\n",
      "          1599.2925, -13584.2939,   -144.0100,   5783.4014,  16867.9785,\n",
      "         -6305.2822,   9281.6240,   1580.8621,  -1114.4478,  -8477.3447,\n",
      "         14638.1963,   2998.3777,   4528.4712,  -2231.8879,   8369.2627,\n",
      "        -16606.7402, -11122.0244,  -3333.1096,  -3668.2979,   8369.0957,\n",
      "         -2694.9465,   2972.6848,   6747.2925,   1265.0015,  15045.9678,\n",
      "        -17581.2637, -14887.4648,  -7127.6865,  -2450.2603,  12545.0674,\n",
      "         -1099.8911,  11564.9980,   4615.2891,  -3728.1431,  -2425.9504],\n",
      "       device='cuda:0')\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(4528.4712, device='cuda:0')\n",
      "45 1\n",
      "tensor(-2425.9504, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))[0].sigmoid()\n",
    "pp(res.shape)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(1., device='cuda:0')\n",
      "45 1\n",
      "tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/ag_news/reporters/layer_47.pt', map_location=device)\n",
    "reporter.eval()\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache['mlp_out', 47][0]).sigmoid()\n",
    "    #res = reporter(cache[47].to(device))[0].sigmoid()\n",
    "pp(res.shape)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([45])\n",
      "[(23, 0), (45, 1)]\n",
      "23 0\n",
      "tensor(0.4922, device='cuda:0')\n",
      "45 1\n",
      "tensor(0.4468, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "t_strs = [s.replace('Ġ', ' ') for s in tokenizer.convert_ids_to_tokens(dataset[0][0])]\n",
    "pp(t_strs)\n",
    "cv.tokens.colored_tokens(t_strs, res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Was',\n",
      " ' the',\n",
      " ' Lind',\n",
      " 'ber',\n",
      " 'gh',\n",
      " ' kidnapping',\n",
      " ' ever',\n",
      " ' solved',\n",
      " '?',\n",
      " ' Yes',\n",
      " ',',\n",
      " ' Hau',\n",
      " 'pt',\n",
      " 'mann',\n",
      " ' was',\n",
      " ' sentenced',\n",
      " ',',\n",
      " ' although',\n",
      " ' he',\n",
      " ' denied',\n",
      " ' his',\n",
      " ' guilt',\n",
      " '.',\n",
      " 'Was',\n",
      " ' the',\n",
      " ' Lind',\n",
      " 'ber',\n",
      " 'gh',\n",
      " ' kidnapping',\n",
      " ' ever',\n",
      " ' solved',\n",
      " '?',\n",
      " ' No',\n",
      " ',',\n",
      " ' the',\n",
      " ' Lind',\n",
      " 'ber',\n",
      " 'gh',\n",
      " ' kidnapping',\n",
      " ' is',\n",
      " ' a',\n",
      " ' famous',\n",
      " ' cold',\n",
      " ' case',\n",
      " '.']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-0ae90b6f-9365\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.40.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-0ae90b6f-9365\",\n",
       "      ColoredTokens,\n",
       "      {\"tokens\": [\"Was\", \" the\", \" Lind\", \"ber\", \"gh\", \" kidnapping\", \" ever\", \" solved\", \"?\", \" Yes\", \",\", \" Hau\", \"pt\", \"mann\", \" was\", \" sentenced\", \",\", \" although\", \" he\", \" denied\", \" his\", \" guilt\", \".\", \"Was\", \" the\", \" Lind\", \"ber\", \"gh\", \" kidnapping\", \" ever\", \" solved\", \"?\", \" No\", \",\", \" the\", \" Lind\", \"ber\", \"gh\", \" kidnapping\", \" is\", \" a\", \" famous\", \" cold\", \" case\", \".\"], \"values\": [0.41417935490608215, 0.4834701716899872, 0.4356457591056824, 0.5251880288124084, 0.46403831243515015, 0.47324177622795105, 0.4862334132194519, 0.5004411339759827, 0.47724395990371704, 0.45991596579551697, 0.47803330421447754, 0.4771656394004822, 0.4310183823108673, 0.4764450490474701, 0.49709415435791016, 0.4416678845882416, 0.5121890902519226, 0.4791909158229828, 0.5489811301231384, 0.47893303632736206, 0.45533621311187744, 0.5019679069519043, 0.49217793345451355, 0.44440141320228577, 0.48828786611557007, 0.5871379971504211, 0.74769127368927, 0.47224563360214233, 0.5028830766677856, 0.52021324634552, 0.4893573224544525, 0.466933935880661, 0.47084909677505493, 0.43342626094818115, 0.44446101784706116, 0.5915371179580688, 0.744455873966217, 0.471463680267334, 0.4880416989326477, 0.5303717851638794, 0.49809789657592773, 0.45987462997436523, 0.538387656211853, 0.4776061773300171, 0.4467948079109192]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f065239fc10>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "pp(tokenizer.decode(dataset[0][0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Was the Lindbergh kidnapping ever solved? Yes, Hauptmann was sentenced, '\n",
      " 'although he denied his guilt.Was the Lindbergh kidnapping ever solved? No, '\n",
      " 'the Lindbergh kidnapping is a famous cold case.')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "sample = imdb_ds['train']['text'][156]\n",
    "sample_false = f'{sample}\\nDid the reviewer find this movie good or bad?\\nGood'\n",
    "sample_true = f'{sample}\\nDid the reviewer find this movie good or bad?\\n Bad'\n",
    "with torch.inference_mode():\n",
    "    _, cache_false = gpt2_xl.run_with_cache(sample_false, remove_batch_dim=True)\n",
    "    _, cache = gpt2_xl.run_with_cache(sample_true, remove_batch_dim=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "layers = 48\n",
    "heads = gpt2_xl.cfg.n_heads\n",
    "head_layer_score = torch.zeros((layers, heads + 1))\n",
    "for layer in range(layers):\n",
    "    probe = elk.training.Reporter.load(\n",
    "        f'./data/gpt2-xl/imdb/festive-elion/reporters/layer_{layer}.pt', \n",
    "        map_location=device\n",
    "    )\n",
    "    pp(probe)\n",
    "    act0 = cache_false['mlp_out', layer][-1].to(device)\n",
    "    act1 = cache['mlp_out', layer][-1].to(device)\n",
    "    p0 = probe(act0).item() # (act0 @ probe['probe.0.weight'].T + probe['probe.0.bias']).sigmoid().item()\n",
    "    p1 = probe(act1).item() # (act1 @ probe['probe.0.weight'].T + probe['probe.0.bias']).sigmoid().item()\n",
    "    confidence = 0.5*(p0 + (1-p1))\n",
    "    pp(f'l {layer} {p0=} {p1=} {confidence=}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 0 p0=-5.12468941451516e-05 p1=-5.094191146781668e-05 '\n",
      " 'confidence=0.49999984750866133')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 1 p0=0.0026898588985204697 p1=-1.0661282539367676 '\n",
      " 'confidence=1.034409056417644')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 2 p0=-0.02765388786792755 p1=0.011869637295603752 '\n",
      " 'confidence=0.48023823741823435')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 3 p0=-0.3130084276199341 p1=0.04913277179002762 '\n",
      " 'confidence=0.31892940029501915')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 4 p0=-0.2435547560453415 p1=-0.06580324470996857 '\n",
      " 'confidence=0.41112424433231354')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 5 p0=0.2913986146450043 p1=0.22199563682079315 confidence=0.5347014889121056'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 6 p0=-0.17497467994689941 p1=0.16652165353298187 '\n",
      " 'confidence=0.32925183326005936')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 7 p0=0.15725861489772797 p1=0.13456983864307404 confidence=0.511344388127327'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 8 p0=-0.30041271448135376 p1=0.06236861273646355 '\n",
      " 'confidence=0.31860933639109135')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 9 p0=0.24706369638442993 p1=0.1910070925951004 confidence=0.5280283018946648'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 10 p0=0.0816621407866478 p1=-0.014310663565993309 '\n",
      " 'confidence=0.5479864021763206')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 11 p0=-0.18970642983913422 p1=-0.19929853081703186 '\n",
      " 'confidence=0.5047960504889488')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 12 p0=0.023690031841397285 p1=-0.03608355671167374 '\n",
      " 'confidence=0.5298867942765355')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 13 p0=-0.08056947588920593 p1=-0.10862977057695389 '\n",
      " 'confidence=0.514030147343874')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 14 p0=-0.003193722339347005 p1=-0.0005347027909010649 '\n",
      " 'confidence=0.49867049022577703')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 15 p0=0.03121110424399376 p1=0.04539857059717178 '\n",
      " 'confidence=0.492906266823411')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 16 p0=-0.011756852269172668 p1=0.0018484903266653419 '\n",
      " 'confidence=0.493197328702081')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 17 p0=-0.043056607246398926 p1=0.13950444757938385 '\n",
      " 'confidence=0.4087194725871086')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 18 p0=0.05655364319682121 p1=0.07752618193626404 '\n",
      " 'confidence=0.4895137306302786')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 19 p0=-0.019121501594781876 p1=0.0304938443005085 '\n",
      " 'confidence=0.4751923270523548')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 20 p0=-0.10810335725545883 p1=-0.2365996390581131 '\n",
      " 'confidence=0.5642481409013271')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 21 p0=2.106881856918335 p1=0.5376496315002441 confidence=1.2846161127090454'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 22 p0=0.022982925176620483 p1=-1.0179836750030518 '\n",
      " 'confidence=1.0204833000898361')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 23 p0=-0.40507981181144714 p1=0.5569232106208801 '\n",
      " 'confidence=0.018998488783836365')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 24 p0=-0.3372548520565033 p1=0.8407968282699585 '\n",
      " 'confidence=-0.0890258401632309')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 25 p0=-1.855039119720459 p1=0.3080587387084961 '\n",
      " 'confidence=-0.5815489292144775')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 26 p0=1.1701024770736694 p1=0.2757090628147125 confidence=0.9471967071294785'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 27 p0=2.7249975204467773 p1=1.7268446683883667 confidence=0.9990764260292053'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 28 p0=1.6411346197128296 p1=1.1183946132659912 confidence=0.7613700032234192'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 29 p0=-1.9652099609375 p1=-0.14075636863708496 '\n",
      " 'confidence=-0.4122267961502075')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 30 p0=0.8359304666519165 p1=-0.3822736144065857 confidence=1.109102040529251'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 31 p0=1.014763593673706 p1=0.31603607535362244 confidence=0.8493637591600418'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 32 p0=0.14206944406032562 p1=-0.27255088090896606 '\n",
      " 'confidence=0.7073101624846458')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 33 p0=0.9044985771179199 p1=-0.19894039630889893 '\n",
      " 'confidence=1.0517194867134094')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 34 p0=-0.5214230418205261 p1=-0.3882485330104828 '\n",
      " 'confidence=0.43341274559497833')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 35 p0=-0.5964718461036682 p1=-0.7514035105705261 '\n",
      " 'confidence=0.577465832233429')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 36 p0=0.3932897746562958 p1=0.23990663886070251 '\n",
      " 'confidence=0.5766915678977966')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 37 p0=-0.9032710194587708 p1=-0.7103402018547058 '\n",
      " 'confidence=0.40353459119796753')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 38 p0=-0.18652063608169556 p1=-0.46265116333961487 '\n",
      " 'confidence=0.6380652636289597')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 39 p0=-0.7017467617988586 p1=-0.36320045590400696 '\n",
      " 'confidence=0.33072684705257416')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 40 p0=-0.37735527753829956 p1=-0.3456859588623047 '\n",
      " 'confidence=0.48416534066200256')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 41 p0=-0.025357160717248917 p1=0.07960601896047592 '\n",
      " 'confidence=0.4475184101611376')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 42 p0=0.3353484272956848 p1=0.4685998558998108 confidence=0.433374285697937'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 43 p0=-0.7788880467414856 p1=-0.7256093621253967 '\n",
      " 'confidence=0.47336065769195557')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 44 p0=-0.6982145309448242 p1=-0.4569503664970398 '\n",
      " 'confidence=0.3793679177761078')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "'l 45 p0=0.6090052723884583 p1=0.5053107142448425 confidence=0.5518472790718079'\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 46 p0=-0.5910739302635193 p1=-1.1679078340530396 '\n",
      " 'confidence=0.7884169518947601')\n",
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "('l 47 p0=-0.05919225513935089 p1=0.18498992919921875 '\n",
      " 'confidence=0.3779089078307152')\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}