_type_: elk.training.train.Elicit
concatenated_layer_offset: 0
data:
  _type_: elk.extraction.extraction.Extract
  binarize: false
  data_dirs: []
  datasets:
  - imdb
  int8: false
  layers: []
  max_examples:
  - 1000
  - 1000
  model: /workspace/llama/llama-2-7b-converted
  num_shots: 0
  num_variants: -1
  seed: 42
  template_path: null
  token_loc: last
  use_encoder_states: false
debug: false
min_gpu_mem: null
net:
  _type_: elk.training.ccs_reporter.CcsConfig
  activation: gelu
  bias: true
  hidden_size: null
  init: default
  loss:
  - 1.0*ccs
  loss_dict:
    ccs: 1.0
  lr: 0.01
  num_epochs: 1000
  num_layers: 1
  num_tries: 10
  optimizer: lbfgs
  pre_ln: false
  seed: 42
  supervised_weight: 0.0
  weight_decay: 0.01
num_gpus: -1
out_dir: /workspace/llama/llama-2-7b-converted/imdb/confident-cohen
prompt_indices: []
supervised: single
