{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pprint import pp\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens import utils, HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "import elk \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/root/.local/share/virtualenvs/artem_capstone-h3n8YrzE/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Warning. This takes a lot of memory (+16GB).\n",
    "gpt2_xl: HookedTransformer = HookedTransformer.from_pretrained(\"gpt2-xl\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "sample = imdb_ds['train']['text'][156]\n",
    "sample_false = f'{sample}\\nDid the reviewer find this movie good or bad?\\nGood'\n",
    "sample_true = f'{sample}\\nDid the reviewer find this movie good or bad?\\n Bad'\n",
    "with torch.inference_mode():\n",
    "    _, cache_false = gpt2_xl.run_with_cache(sample_false, remove_batch_dim=True)\n",
    "    _, cache_true = gpt2_xl.run_with_cache(sample_true, remove_batch_dim=True)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'imdb_ds' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 2\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=61'>62</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=62'>63</a>\u001b[0m sample \u001b[39m=\u001b[39m imdb_ds[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m156\u001b[39m]\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=63'>64</a>\u001b[0m sample_false \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msample\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mDid the reviewer find this movie good or bad?\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mGood\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=64'>65</a>\u001b[0m sample_true \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msample\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mDid the reviewer find this movie good or bad?\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Bad\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'imdb_ds' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "probe_pt = torch.load(f'./data/gpt2-xl/imdb/festive-elion/reporters/layer_47.pt')\n",
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/imdb/festive-elion/reporters/layer_47.pt', map_location=device)\n",
    "#reporter.eval()\n",
    "#reporter = elk.training.CcsReporter(elk.training.CcsReporterConfig(), in_features=probe_pt['in_features'])\n",
    "pp(reporter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 670.23it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = []\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x += tokens\n",
    "            inx = len(tokens) + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if len(x) > 1:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "([tensor([16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  1400,\n",
      "           11,   262,  9329,   527,   456, 25201,   318,   257,  5863,  4692,\n",
      "         1339,    13]),\n",
      "  tensor([16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  1400,\n",
      "           11,   262,  9329,   527,   456, 25201,   373,  1239, 16019,    13])],\n",
      " [(1, 1), (2, 1)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 765.66it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat(x, tokens)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if len(x) > 1:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "concat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mconcat(x, tokens)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mTypeError\u001b[0m: concat() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.cat((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if len(x) > 1:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 17\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m             inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m             y\u001b[39m.\u001b[39mappend((inx, label))\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=116'>117</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(x) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=117'>118</a>\u001b[0m         dataset\u001b[39m.\u001b[39mappend((x, y))\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=118'>119</a>\u001b[0m pp(dataset[\u001b[39m0\u001b[39m])        \n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 754.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.cat((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if len(x) > 1:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 17\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m             inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m             y\u001b[39m.\u001b[39mappend((inx, label))\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=116'>117</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(x) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=117'>118</a>\u001b[0m         dataset\u001b[39m.\u001b[39mappend((x, y))\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=118'>119</a>\u001b[0m pp(dataset[\u001b[39m0\u001b[39m])        \n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 768.89it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.cat((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  1400,\n",
      "            11,   262,  9329,   527,   456, 25201,   318,   257,  5863,  4692,\n",
      "          1339,    13, 16973,   262,  9329,   527,   456, 25201,  1683, 16019,\n",
      "            30,  1400,    11,   262,  9329,   527,   456, 25201,   373,  1239,\n",
      "         16019,    13]]),\n",
      " [(1, 1), (2, 1)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 741.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.stack((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 22] at entry 0 and [1, 23] at entry 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack((x, tokens), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 22] at entry 0 and [1, 23] at entry 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.stack((x, tokens), 0)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 20] at entry 0 and [1, 24] at entry 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack((x, tokens), \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 20] at entry 0 and [1, 24] at entry 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.stack((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 24] at entry 0 and [1, 21] at entry 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack((x, tokens), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 24] at entry 0 and [1, 21] at entry 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1).squeeze()\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mconcat((x, tokens), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 751.94it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1).squeeze()\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 14\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=111'>112</a>\u001b[0m \u001b[39mif\u001b[39;00m statements:\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=112'>113</a>\u001b[0m     tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode( statements\u001b[39m.\u001b[39mpop(), return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=113'>114</a>\u001b[0m     x \u001b[39m=\u001b[39m tokens \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39;49mconcat((x, tokens), \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=114'>115</a>\u001b[0m     inx \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m (y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m y \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m     y\u001b[39m.\u001b[39mappend((inx, label))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 829.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1)\n",
    "            inx = tokens.shape[0] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  3363,\n",
      "            11, 49696,   457,  9038,   373, 11897,    11,  3584,   339,  6699,\n",
      "           465, 14934,    13, 16973,   262,  9329,   527,   456, 25201,  1683,\n",
      "         16019,    30,  1400,    11,   262,  9329,   527,   456, 25201,   318,\n",
      "           257,  5863,  4692,  1339,    13, 16973,   262,  9329,   527,   456,\n",
      "         25201,  1683, 16019,    30,  1400,    11,   262,  9329,   527,   456,\n",
      "         25201,   373,  1239, 16019,    13, 16973,   262,  9329,   527,   456,\n",
      "         25201,  1683, 16019,    30,  3363,    11,   262,  1339,   373, 16019,\n",
      "            11,  3584,   612,   389,   991,   867,  5559, 10946,    13]]),\n",
      " [(1, 0), (2, 1), (3, 1), (4, 0)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 772.15it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1)\n",
    "            inx = tokens.shape[1] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([[16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  1400,\n",
      "            11,   262,  9329,   527,   456, 25201,   318,   257,  5863,  4692,\n",
      "          1339,    13, 16973,   262,  9329,   527,   456, 25201,  1683, 16019,\n",
      "            30,  1400,    11,   262,  9329,   527,   456, 25201,   373,  1239,\n",
      "         16019,    13, 16973, 10584, 34405,  6776,   618,   673,  2627,   257,\n",
      "         32292,    30,  3363,    11, 10584, 34405,  2627,   257, 32292,   878,\n",
      "           607,  1918,    13, 16973,   262,  9329,   527,   456, 25201,  1683,\n",
      "         16019,    30,  3363,    11, 49696,   457,  9038,   373, 11897,    11,\n",
      "          3584,   339,  6699,   465, 14934,    13]]),\n",
      " [(22, 1), (42, 1), (63, 1), (86, 0)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 768.33it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1)\n",
    "            inx = tokens.shape[1] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        x._squeeze(0)\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_squeeze'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 18\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=115'>116</a>\u001b[0m             y\u001b[39m.\u001b[39mappend((inx, label))\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=116'>117</a>\u001b[0m     \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///root/artem_capstone/dlk.py?line=117'>118</a>\u001b[0m         x\u001b[39m.\u001b[39;49m_squeeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=118'>119</a>\u001b[0m         dataset\u001b[39m.\u001b[39mappend((x, y))\n\u001b[1;32m     <a href='file:///root/artem_capstone/dlk.py?line=119'>120</a>\u001b[0m pp(dataset[\u001b[39m0\u001b[39m])        \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_squeeze'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "truthfulqa = load_dataset('truthful_qa', 'generation')\n",
    "# Construct statements from each correct_answer and incorrect_answer:\n",
    "correct_statements = []\n",
    "incorrect_statements = []\n",
    "for e in truthfulqa['validation']:\n",
    "    for correct_answer in e['correct_answers']:\n",
    "        correct_statements.append(f\"{e['question']} {correct_answer}.\")\n",
    "    for incorrect_answer in e['incorrect_answers']:\n",
    "        incorrect_statements.append(f\"{e['question']} {incorrect_answer}.\")\n",
    "pp(len(incorrect_statements))\n",
    "pp(len(correct_statements))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Found cached dataset truthful_qa (/root/.cache/huggingface/datasets/truthful_qa/generation/1.1.0/63502f6bc6ee493830ce0843991b028d0ab568d221896b2ee3b8a5dfdaa9d7f4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 772.29it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3318\n",
      "2600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Create dataset with x as concatenated correct and incorrect 2..4 statements,\n",
    "# and y as several 0 or 1 depending on whether a correct or incorrect statement is the correct answer.\n",
    "dataset = []    \n",
    "tokenizer = gpt2_xl.tokenizer\n",
    "while correct_statements or incorrect_statements:\n",
    "    x : torch.Tensor = None\n",
    "    y = []\n",
    "    for _ in range(np.random.randint(2, 5)):\n",
    "        label =  np.random.randint(2)\n",
    "        statements = (correct_statements, incorrect_statements)[label]\n",
    "        if statements:\n",
    "            tokens = tokenizer.encode( statements.pop(), return_tensors='pt')\n",
    "            x = tokens if x is None else torch.concat((x, tokens), -1)\n",
    "            inx = tokens.shape[1] + (y[-1][0] if y else 0)\n",
    "            y.append((inx, label))\n",
    "    if x is not None:\n",
    "        x.squeeze_(0)\n",
    "        dataset.append((x, y))\n",
    "pp(dataset[0])        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(tensor([16973,   262,  9329,   527,   456, 25201,  1683, 16019,    30,  1400,\n",
      "           11,   262,  9329,   527,   456, 25201,   318,   257,  5863,  4692,\n",
      "         1339,    13, 16973,   262,  9329,   527,   456, 25201,  1683, 16019,\n",
      "           30,  3363,    11, 49696,   457,  9038,   373, 11897,    11,  3584,\n",
      "          339,  6699,   465, 14934,    13, 16973,   262,  9329,   527,   456,\n",
      "        25201,  1683, 16019,    30,  1400,    11,   262,  9329,   527,   456,\n",
      "        25201,   373,  1239, 16019,    13]),\n",
      " [(22, 1), (45, 0), (65, 1)])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "_, cache_true = gpt2_xl.run_with_cache(dataset[0][0])\n",
    "pp(cache_true['mlp_out', 47].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 65, 1600])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "with torch.inference_mode():\n",
    "    _, cache_true = gpt2_xl.run_with_cache(dataset[0][0])\n",
    "    pp(cache_true['mlp_out', 47].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 65, 1600])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "reporter = elk.training.Reporter.load(f'./data/gpt2-xl/dbpedia_14/reporters/layer_47.pt', map_location=device)\n",
    "pp(reporter)\n",
    "#reporter.eval()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CcsReporter(\n",
      "  (norm): ConceptEraser()\n",
      "  (probe): Sequential(\n",
      "    (0): Linear(in_features=1600, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47])\n",
    "pp(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.6682,  0.0199, -1.3783, -0.9652, -0.6717, -0.4928, -0.0098, -0.7509,\n",
      "         -1.0097, -0.5375, -0.2278,  0.3518, -0.8119, -0.4802, -0.7038, -0.1854,\n",
      "          0.0605, -0.7238, -0.4953, -0.2556, -0.3655, -0.5478, -0.4605,  0.0284,\n",
      "         -0.8200,  0.0843, -0.5844, -0.6552, -0.2692, -0.5147, -1.1528, -0.4228,\n",
      "         -0.1960, -1.3324, -0.6458, -0.1453,  0.1380, -0.1760,  0.5313,  0.2348,\n",
      "         -0.0870, -0.4663, -0.3689, -0.4570, -0.9262,  0.3502, -0.3292, -0.1541,\n",
      "          0.7350, -0.6247, -0.0878,  0.9900,  0.0053, -0.9718, -0.2322, -0.0569,\n",
      "          0.2120, -0.3424,  0.6904, -1.0462, -0.2487, -0.2962, -0.6078, -0.5993,\n",
      "         -1.0041]], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][-1])\n",
    "pp(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.6682,  0.0199, -1.3783, -0.9652, -0.6717, -0.4928, -0.0098, -0.7509,\n",
      "        -1.0097, -0.5375, -0.2278,  0.3518, -0.8119, -0.4802, -0.7038, -0.1854,\n",
      "         0.0605, -0.7238, -0.4953, -0.2556, -0.3655, -0.5478, -0.4605,  0.0284,\n",
      "        -0.8200,  0.0843, -0.5844, -0.6552, -0.2692, -0.5147, -1.1528, -0.4228,\n",
      "        -0.1960, -1.3324, -0.6458, -0.1453,  0.1380, -0.1760,  0.5313,  0.2348,\n",
      "        -0.0870, -0.4663, -0.3689, -0.4570, -0.9262,  0.3502, -0.3292, -0.1541,\n",
      "         0.7350, -0.6247, -0.0878,  0.9900,  0.0053, -0.9718, -0.2322, -0.0569,\n",
      "         0.2120, -0.3424,  0.6904, -1.0462, -0.2487, -0.2962, -0.6078, -0.5993,\n",
      "        -1.0041], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][-1])\n",
    "pp(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.6682,  0.0199, -1.3783, -0.9652, -0.6717, -0.4928, -0.0098, -0.7509,\n",
      "        -1.0097, -0.5375, -0.2278,  0.3518, -0.8119, -0.4802, -0.7038, -0.1854,\n",
      "         0.0605, -0.7238, -0.4953, -0.2556, -0.3655, -0.5478, -0.4605,  0.0284,\n",
      "        -0.8200,  0.0843, -0.5844, -0.6552, -0.2692, -0.5147, -1.1528, -0.4228,\n",
      "        -0.1960, -1.3324, -0.6458, -0.1453,  0.1380, -0.1760,  0.5313,  0.2348,\n",
      "        -0.0870, -0.4663, -0.3689, -0.4570, -0.9262,  0.3502, -0.3292, -0.1541,\n",
      "         0.7350, -0.6247, -0.0878,  0.9900,  0.0053, -0.9718, -0.2322, -0.0569,\n",
      "         0.2120, -0.3424,  0.6904, -1.0462, -0.2487, -0.2962, -0.6078, -0.5993,\n",
      "        -1.0041], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0, -1])\n",
    "pp(res)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(-1.0041, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0, -1])\n",
    "pp(res.sigmoid())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.2681, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0])\n",
    "pp(res.sigmoid())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0])\n",
    "pp(res.sigmoid())\n",
    "pp(dataset[0][1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n",
      "[(22, 1), (45, 0), (65, 1)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0])\n",
    "#pp(res.sigmoid())\n",
    "#pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    pp(res[inx].sigmoid())\n",
    "    pp(label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.3869, device='cuda:0')\n",
      "1\n",
      "tensor(0.5867, device='cuda:0')\n",
      "0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 65 is out of bounds for dimension 0 with size 65",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 7\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=133'>134</a>\u001b[0m \u001b[39m#pp(res.sigmoid())\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m \u001b[39m#pp(dataset[0][1])\u001b[39;00m\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=136'>137</a>\u001b[0m     pp(res[inx]\u001b[39m.\u001b[39msigmoid())\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=137'>138</a>\u001b[0m     pp(label)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 65 is out of bounds for dimension 0 with size 65"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "for inx, label in dataset[0][1]:\n",
    "    pp(res[inx])\n",
    "    pp(label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.3869, device='cuda:0')\n",
      "1\n",
      "tensor(0.5867, device='cuda:0')\n",
      "0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 65 is out of bounds for dimension 0 with size 65",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 5\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=132'>133</a>\u001b[0m     res \u001b[39m=\u001b[39m reporter(cache_true[\u001b[39m'\u001b[39m\u001b[39mmlp_out\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m47\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39msigmoid()\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=133'>134</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m     pp(res[inx])\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m     pp(label)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 65 is out of bounds for dimension 0 with size 65"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "for inx, label in dataset[0][1]:\n",
    "    pp(res[0, inx])\n",
    "    pp(label)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 5\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=132'>133</a>\u001b[0m     res \u001b[39m=\u001b[39m reporter(cache_true[\u001b[39m'\u001b[39m\u001b[39mmlp_out\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m47\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39msigmoid()\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=133'>134</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m     pp(res[\u001b[39m0\u001b[39;49m, inx])\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m     pp(label)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "pp(res)\n",
    "for inx, label in dataset[0][1]:\n",
    "    pp(res[0, inx])\n",
    "    pp(label)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 6\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=133'>134</a>\u001b[0m pp(res)\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m     pp(res[\u001b[39m0\u001b[39;49m, inx])\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=136'>137</a>\u001b[0m     pp(label)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "pp(res)\n",
    "for inx, label in dataset[0][1]:\n",
    "    pp(inx, label)\n",
    "    pp(res[0, inx])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'write'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 6\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=133'>134</a>\u001b[0m pp(res)\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m     pp(inx, label)\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=136'>137</a>\u001b[0m     pp(res[\u001b[39m0\u001b[39m, inx])\n",
      "File \u001b[0;32m/usr/lib/python3.10/pprint.py:66\u001b[0m, in \u001b[0;36mpp\u001b[0;34m(object, sort_dicts, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=63'>64</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpp\u001b[39m(\u001b[39mobject\u001b[39m, \u001b[39m*\u001b[39margs, sort_dicts\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=64'>65</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pretty-print a Python object\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///usr/lib/python3.10/pprint.py?line=65'>66</a>\u001b[0m     pprint(\u001b[39mobject\u001b[39;49m, \u001b[39m*\u001b[39;49margs, sort_dicts\u001b[39m=\u001b[39;49msort_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pprint.py:55\u001b[0m, in \u001b[0;36mpprint\u001b[0;34m(object, stream, indent, width, depth, compact, sort_dicts, underscore_numbers)\u001b[0m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=49'>50</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Pretty-print a Python object to a stream [default is sys.stdout].\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=50'>51</a>\u001b[0m printer \u001b[39m=\u001b[39m PrettyPrinter(\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=51'>52</a>\u001b[0m     stream\u001b[39m=\u001b[39mstream, indent\u001b[39m=\u001b[39mindent, width\u001b[39m=\u001b[39mwidth, depth\u001b[39m=\u001b[39mdepth,\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=52'>53</a>\u001b[0m     compact\u001b[39m=\u001b[39mcompact, sort_dicts\u001b[39m=\u001b[39msort_dicts,\n\u001b[1;32m     <a href='file:///usr/lib/python3.10/pprint.py?line=53'>54</a>\u001b[0m     underscore_numbers\u001b[39m=\u001b[39munderscore_numbers)\n\u001b[0;32m---> <a href='file:///usr/lib/python3.10/pprint.py?line=54'>55</a>\u001b[0m printer\u001b[39m.\u001b[39;49mpprint(\u001b[39mobject\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pprint.py:152\u001b[0m, in \u001b[0;36mPrettyPrinter.pprint\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/pprint.py?line=150'>151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpprint\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mobject\u001b[39m):\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/pprint.py?line=151'>152</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format(\u001b[39mobject\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, {}, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/pprint.py?line=152'>153</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pprint.py:193\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/pprint.py?line=190'>191</a>\u001b[0m         \u001b[39mdel\u001b[39;00m context[objid]\n\u001b[1;32m    <a href='file:///usr/lib/python3.10/pprint.py?line=191'>192</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.10/pprint.py?line=192'>193</a>\u001b[0m stream\u001b[39m.\u001b[39;49mwrite(rep)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'write'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "pp(res)\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[0, inx])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n",
      "22 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 7\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=134'>135</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m     \u001b[39mprint\u001b[39m(inx, label)\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=136'>137</a>\u001b[0m     pp(res[\u001b[39m0\u001b[39;49m, inx])\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n",
      "[(22, 1), (45, 0), (65, 1)]\n",
      "22 1\n",
      "tensor(0.3869, device='cuda:0')\n",
      "45 0\n",
      "tensor(0.5867, device='cuda:0')\n",
      "65 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 65 is out of bounds for dimension 0 with size 65",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/root/artem_capstone/dlk.py\u001b[0m in \u001b[0;36mline 8\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=135'>136</a>\u001b[0m \u001b[39mfor\u001b[39;00m inx, label \u001b[39min\u001b[39;00m dataset[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]:\n\u001b[1;32m      <a href='file:///root/artem_capstone/dlk.py?line=136'>137</a>\u001b[0m     \u001b[39mprint\u001b[39m(inx, label)\n\u001b[0;32m----> <a href='file:///root/artem_capstone/dlk.py?line=137'>138</a>\u001b[0m     pp(res[inx])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 65 is out of bounds for dimension 0 with size 65"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "with torch.inference_mode():\n",
    "    res = reporter(cache_true['mlp_out', 47][0]).sigmoid()\n",
    "pp(res)\n",
    "pp(dataset[0][1])\n",
    "for inx, label in dataset[0][1]:\n",
    "    print(inx, label)\n",
    "    pp(res[inx-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.6611, 0.5050, 0.2013, 0.2758, 0.3381, 0.3792, 0.4976, 0.3206, 0.2670,\n",
      "        0.3688, 0.4433, 0.5870, 0.3075, 0.3822, 0.3310, 0.4538, 0.5151, 0.3266,\n",
      "        0.3787, 0.4364, 0.4096, 0.3664, 0.3869, 0.5071, 0.3058, 0.5211, 0.3579,\n",
      "        0.3418, 0.4331, 0.3741, 0.2400, 0.3959, 0.4512, 0.2088, 0.3439, 0.4637,\n",
      "        0.5344, 0.4561, 0.6298, 0.5584, 0.4783, 0.3855, 0.4088, 0.3877, 0.2837,\n",
      "        0.5867, 0.4184, 0.4616, 0.6759, 0.3487, 0.4781, 0.7291, 0.5013, 0.2745,\n",
      "        0.4422, 0.4858, 0.5528, 0.4152, 0.6660, 0.2599, 0.4381, 0.4265, 0.3526,\n",
      "        0.3545, 0.2681], device='cuda:0')\n",
      "[(22, 1), (45, 0), (65, 1)]\n",
      "22 1\n",
      "tensor(0.3664, device='cuda:0')\n",
      "45 0\n",
      "tensor(0.2837, device='cuda:0')\n",
      "65 1\n",
      "tensor(0.2681, device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}