{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "VERBOSE = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pp(device)\n",
    "\n",
    "login(add_to_git_credential=True)\n",
    "np_rand = np.random.default_rng(seed=100500)\n",
    "model_type = torch.bfloat16\n",
    "pt_template = \"ggplot2\"\n",
    "EXAMPLES_PER_QUESTION = 2\n",
    "llama_size = '13b'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device(type='cuda')\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8306263c486641319d3447b43bdf6639"
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load model\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    f\"meta-llama/Llama-2-{llama_size}-chat-hf\",\n",
    "    # device_map=device,\n",
    ")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "hf_model = LlamaForCausalLM.from_pretrained(\n",
    "    f\"meta-llama/Llama-2-{llama_size}-chat-hf\",\n",
    "    torch_dtype=model_type,\n",
    "    device_map=device,\n",
    "    low_cpu_mem_usage=True,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ee8583505ba490fab55337ca4d2e3b9"
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bc0338ab5fb44f79c210cc65b92d24e"
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31d29065b27e45409034d30c5c2954d4"
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0afe284eebc344539ef31165f2fbdbf7"
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b7714184ad144689282920eab731349"
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7981372f479c484c80e9dd486bbc2ead"
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f16b02f5989a456e97c0d0b3c0d75c93"
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d61df75667045cfa730c3321ed522fa"
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5881cebcd4764241b6da394d8489f904"
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cad4d59d05004763bb1465bf9b0c5f05"
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "583a102983b54859a5a7e8ce41590d2e"
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96d8f1b6225d45a1b854110012e5c0ee"
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "hf_model.eval()\n",
    "pp(hf_model)\n",
    "pp(hf_model.config)\n",
    "with torch.no_grad():\n",
    "    pp(\n",
    "        tokenizer.batch_decode(\n",
    "            hf_model.generate(\n",
    "                tokenizer(\"The capital of Russia is\", return_tensors=\"pt\").input_ids.to(\n",
    "                    device\n",
    "                ),\n",
    "                max_length=20,\n",
    "            )\n",
    "        )[0]\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "true_ids = [5574, 5852, 1565, 3009]\n",
    "false_ids = [7700, 8824, 2089, 4541]\n",
    "print(\" \".join(f\"'{tokenizer.decode(id_)}'\" for id_ in true_ids))\n",
    "print(\" \".join(f\"'{tokenizer.decode(id_)}'\" for id_ in false_ids))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "truthfulqa = load_dataset(\"truthful_qa\", \"generation\")  # 817 rows\n",
    "env = Environment(loader=PackageLoader(\"utils\"), autoescape=select_autoescape())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b7009dbdbcb4ae0b74233c49b38287f"
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading data: 100%|██████████| 223k/223k [00:00<00:00, 1.02MB/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8afb7f5fed3f4825991bab5bd924e377"
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "truthfulqa = load_dataset(\"truthful_qa\", \"generation\")  # 817 rows\n",
    "env = Environment(loader=PackageLoader(\"utils\"), autoescape=select_autoescape())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Datasets generators:\n",
    "\n",
    "\n",
    "def div_items(items, max_num):\n",
    "    \"\"\" Return max_num items from items, taking equal number of correct and incorrect answers.\"\"\"\n",
    "    if max_num is not None:\n",
    "        for take_correct in (True, False):\n",
    "            div = max_num // 2\n",
    "            rshuffle(items)\n",
    "            for e in items:\n",
    "                if div == 0:\n",
    "                    break\n",
    "                if e[\"is_correct\"] == take_correct:\n",
    "                    div -= 1\n",
    "                    yield e\n",
    "    else:\n",
    "        yield from items\n",
    "\n",
    "\n",
    "def one_statement_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with one statement per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answer.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "            counter += 1\n",
    "            items = [\n",
    "                {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answer\": ans,\n",
    "                    },\n",
    "                }\n",
    "                for is_correct in (True, False)\n",
    "                for ans in (inc_as, cor_as)[is_correct]\n",
    "            ]\n",
    "            yield from div_items(items, max_per_q)\n",
    "\n",
    "\n",
    "def conj_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with two statements in conjunction per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answers.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "\n",
    "            def create_yield(is_correct, answers):\n",
    "                nonlocal counter\n",
    "                counter += 1\n",
    "                return {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answers\": answers,\n",
    "                        \"is_disjunction\": False,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            items = [\n",
    "                create_yield(True, [c_a, other_c_a])\n",
    "                for c_a in cor_as\n",
    "                for other_c_a in [a for a in cor_as if a != c_a]\n",
    "            ] + [\n",
    "                create_yield(False, [i_a, c_a]) for i_a in inc_as for c_a in cor_as\n",
    "            ] + [\n",
    "                create_yield(False, [c_a, i_a]) for i_a in inc_as for c_a in cor_as\n",
    "            ]\n",
    "            yield from div_items(items, max_per_q)\n",
    "\n",
    "\n",
    "def disj_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with two statements in disjunction per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answers.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "\n",
    "            def create_yield(is_correct, answers):\n",
    "                nonlocal counter\n",
    "                counter += 1\n",
    "                return {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answers\": answers,\n",
    "                        \"is_disjunction\": True,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            items = (\n",
    "                [create_yield(True, [c_a, i_a]) for c_a in cor_as for i_a in inc_as]\n",
    "                + [\n",
    "                    create_yield(True, [c_a, other_c_a])\n",
    "                    for c_a in cor_as\n",
    "                    for other_c_a in [a for a in cor_as if a != c_a]\n",
    "                ]\n",
    "                + [\n",
    "                    create_yield(False, [i_a, other_i_a])\n",
    "                    for i_a in inc_as\n",
    "                    for other_i_a in [a for a in inc_as if a != i_a]\n",
    "                ]\n",
    "            )\n",
    "            yield from div_items(items, max_per_q)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Datasets generators:\n",
    "\n",
    "\n",
    "def div_items(items, max_num):\n",
    "    \"\"\" Return max_num items from items, taking equal number of correct and incorrect answers.\"\"\"\n",
    "    if max_num is not None:\n",
    "        for take_correct in (True, False):\n",
    "            div = max_num // 2\n",
    "            rshuffle(items)\n",
    "            for e in items:\n",
    "                if div == 0:\n",
    "                    break\n",
    "                if e[\"is_correct\"] == take_correct:\n",
    "                    div -= 1\n",
    "                    yield e\n",
    "    else:\n",
    "        yield from items\n",
    "\n",
    "\n",
    "def one_statement_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with one statement per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answer.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "            counter += 1\n",
    "            items = [\n",
    "                {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answer\": ans,\n",
    "                    },\n",
    "                }\n",
    "                for is_correct in (True, False)\n",
    "                for ans in (inc_as, cor_as)[is_correct]\n",
    "            ]\n",
    "            yield from div_items(items, max_per_q)\n",
    "\n",
    "\n",
    "def conj_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with two statements in conjunction per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answers.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "\n",
    "            def create_yield(is_correct, answers):\n",
    "                nonlocal counter\n",
    "                counter += 1\n",
    "                return {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answers\": answers,\n",
    "                        \"is_disjunction\": False,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            items = [\n",
    "                create_yield(True, [c_a, other_c_a])\n",
    "                for c_a in cor_as\n",
    "                for other_c_a in [a for a in cor_as if a != c_a]\n",
    "            ] + [\n",
    "                create_yield(False, [i_a, c_a]) for i_a in inc_as for c_a in cor_as\n",
    "            ] + [\n",
    "                create_yield(False, [c_a, i_a]) for i_a in inc_as for c_a in cor_as\n",
    "            ]\n",
    "            yield from div_items(items, max_per_q)\n",
    "\n",
    "\n",
    "def disj_ds_generator(max_per_q=None):\n",
    "    \"\"\" Generator for a dataset with two statements in disjunction per question. \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        template = env.get_template(\"question_answers.jinja\")\n",
    "        counter = 0\n",
    "        for row_id, row in tqdm(list(enumerate(truthfulqa[\"validation\"]))):\n",
    "            inc_as = row[\"incorrect_answers\"]\n",
    "            cor_as = row[\"correct_answers\"]\n",
    "\n",
    "            def create_yield(is_correct, answers):\n",
    "                nonlocal counter\n",
    "                counter += 1\n",
    "                return {\n",
    "                    \"id\": counter,\n",
    "                    \"question_id\": row_id,\n",
    "                    \"row\": row,\n",
    "                    \"template_render_fn\": template.render,\n",
    "                    \"is_correct\": is_correct,\n",
    "                    \"template_render_params\": {\n",
    "                        \"question\": row[\"question\"],\n",
    "                        \"answers\": answers,\n",
    "                        \"is_disjunction\": True,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            items = (\n",
    "                [create_yield(True, [c_a, i_a]) for c_a in cor_as for i_a in inc_as]\n",
    "                + [\n",
    "                    create_yield(True, [c_a, other_c_a])\n",
    "                    for c_a in cor_as\n",
    "                    for other_c_a in [a for a in cor_as if a != c_a]\n",
    "                ]\n",
    "                + [\n",
    "                    create_yield(False, [i_a, other_i_a])\n",
    "                    for i_a in inc_as\n",
    "                    for other_i_a in [a for a in inc_as if a != i_a]\n",
    "                ]\n",
    "            )\n",
    "            yield from div_items(items, max_per_q)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "report = pd.DataFrame()\n",
    "results = pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "report = pd.DataFrame()\n",
    "results = pd.DataFrame()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def fs_calc_accuracy_for(ds_generator, results, report_index_name, max_per_q=None):\n",
    "    \"\"\" Few-shot accuracy calculation for a given dataset generator.\"\"\"\n",
    "\n",
    "    known_questions = set()\n",
    "    wrong_questions = set()\n",
    "    count = 0\n",
    "    correct_n = 0\n",
    "    pbar = tqdm(ds_generator(max_per_q=max_per_q))\n",
    "    ds_true_samples_num = 0\n",
    "    for sample_gen in pbar:\n",
    "        input_ = sample_gen[\"template_render_fn\"](\n",
    "            **sample_gen[\"template_render_params\"], label=\"\"\n",
    "        )\n",
    "        t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "        t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "        outputs = hf_model(**t_output, output_hidden_states=False)\n",
    "        pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "        token = pred.argmax(-1)\n",
    "        is_correct = (\n",
    "            token in true_ids if sample_gen[\"is_correct\"] else token in false_ids\n",
    "        )\n",
    "        if sample_gen[\"is_correct\"]:\n",
    "            ds_true_samples_num += 1\n",
    "        if is_correct:\n",
    "            correct_n += 1\n",
    "            if not sample_gen[\"question_id\"] in wrong_questions:\n",
    "                known_questions.add(sample_gen[\"question_id\"])\n",
    "        else:\n",
    "            wrong_questions.add(sample_gen[\"question_id\"])\n",
    "            known_questions.discard(sample_gen[\"question_id\"])\n",
    "        count += 1\n",
    "        pbar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, known {len(known_questions)}\"\n",
    "        )\n",
    "    assert count > 0\n",
    "    # Add to results new row:\n",
    "    results\n",
    "    return known_questions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def fs_calc_accuracy_for(ds_generator, results, report_index_name, max_per_q=None):\n",
    "    \"\"\" Few-shot accuracy calculation for a given dataset generator.\"\"\"\n",
    "\n",
    "    known_questions = set()\n",
    "    wrong_questions = set()\n",
    "    count = 0\n",
    "    correct_n = 0\n",
    "    pbar = tqdm(ds_generator(max_per_q=max_per_q))\n",
    "    ds_true_samples_num = 0\n",
    "    for sample_gen in pbar:\n",
    "        input_ = sample_gen[\"template_render_fn\"](\n",
    "            **sample_gen[\"template_render_params\"], label=\"\"\n",
    "        )\n",
    "        t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "        t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "        outputs = hf_model(**t_output, output_hidden_states=False)\n",
    "        pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "        token = pred.argmax(-1)\n",
    "        is_correct = (\n",
    "            token in true_ids if sample_gen[\"is_correct\"] else token in false_ids\n",
    "        )\n",
    "        if sample_gen[\"is_correct\"]:\n",
    "            ds_true_samples_num += 1\n",
    "        if is_correct:\n",
    "            correct_n += 1\n",
    "            if not sample_gen[\"question_id\"] in wrong_questions:\n",
    "                known_questions.add(sample_gen[\"question_id\"])\n",
    "        else:\n",
    "            wrong_questions.add(sample_gen[\"question_id\"])\n",
    "            known_questions.discard(sample_gen[\"question_id\"])\n",
    "        count += 1\n",
    "        pbar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, known {len(known_questions)}\"\n",
    "        )\n",
    "    assert count > 0\n",
    "    # Add to results new row:\n",
    "    results\n",
    "    return known_questions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# FS - one statement\n",
    "\n",
    "fs_one_known_qs = fs_calc_accuracy_for(\n",
    "    one_statement_ds_generator, results, \"One statement\", max_per_q=EXAMPLES_PER_QUESTION\n",
    ")\n",
    "display(results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 817/817 [01:44<00:00,  7.83it/s]84: : 1633it [01:44, 14.91it/s]\n",
      "Correct 974, count 1634, accuracy 0.5961, known 284: : 1634it [01:44, 15.64it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# FS - one statement\n",
    "\n",
    "fs_one_known_qs = fs_calc_accuracy_for(\n",
    "    one_statement_ds_generator, results, \"One statement\", max_per_q=EXAMPLES_PER_QUESTION\n",
    ")\n",
    "display(results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 817/817 [01:46<00:00,  7.66it/s]83: : 1633it [01:46, 14.43it/s]\n",
      "Correct 977, count 1634, accuracy 0.5979, known 283: : 1634it [01:46, 15.32it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# FS - disjunction\n",
    "fs_disj_known_qs = fs_calc_accuracy_for(\n",
    "    disj_ds_generator, report, \"Disjunction\", max_per_q=EXAMPLES_PER_QUESTION\n",
    ")\n",
    "display(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 817/817 [02:14<00:00,  6.07it/s]8: : 1591it [02:14, 11.45it/s]\n",
      "Correct 599, count 1591, accuracy 0.3765, known 98: : 1591it [02:14, 11.81it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# FS - disjunction\n",
    "fs_disj_known_qs = fs_calc_accuracy_for(\n",
    "    disj_ds_generator, report, \"Disjunction\", max_per_q=EXAMPLES_PER_QUESTION\n",
    ")\n",
    "display(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 817/817 [02:14<00:00,  6.06it/s]9: : 1591it [02:14, 11.47it/s]\n",
      "Correct 577, count 1591, accuracy 0.3627, known 89: : 1591it [02:14, 11.80it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# FS - conjunction\n",
    "fs_conj_known_qs = fs_calc_accuracy_for(\n",
    "    conj_ds_generator, report, \"Conjunction\", max_per_q=EXAMPLES_PER_QUESTION\n",
    ")\n",
    "display(report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 817/817 [02:12<00:00,  6.18it/s]9: : 1563it [02:12, 11.57it/s]\n",
      "Correct 680, count 1564, accuracy 0.4348, known 79: : 1564it [02:12, 11.82it/s]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "report.to_csv(f\"data/llama{llama_size}/truthful_qa_report_data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "report.to_csv(f\"data/llama{llama_size}/truthful_qa_report_data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Dataset for hidden states:\n",
    "\n",
    "\n",
    "def create_tensordataset(ds_generator, hf_model, tokenizer, max_per_q=None, layer=-1):\n",
    "    with torch.no_grad():\n",
    "        items = list(ds_generator(max_per_q))\n",
    "        neg_hs = []\n",
    "        pos_hs = []\n",
    "        gt_labels = []  # Ground truth labels.\n",
    "        ids = []\n",
    "        q_ids = []\n",
    "        for item in tqdm(items):\n",
    "            for label in (True, False):\n",
    "                input_ = item[\"template_render_fn\"](\n",
    "                    **item[\"template_render_params\"], label=str(label)\n",
    "                )\n",
    "                t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "                t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "                output = hf_model(**t_output, output_hidden_states=True)\n",
    "                hs = output.hidden_states[layer][0, -1].detach()\n",
    "                if label:\n",
    "                    pos_hs.append(hs)\n",
    "                else:\n",
    "                    neg_hs.append(hs)\n",
    "            gt_labels.append(item[\"is_correct\"])\n",
    "            ids.append(item[\"id\"])\n",
    "            q_ids.append(item[\"question_id\"])\n",
    "\n",
    "        neg_hs = torch.stack(neg_hs).type(torch.float)\n",
    "        pos_hs = torch.stack(pos_hs).type(torch.float)\n",
    "        gt_labels = torch.tensor(gt_labels).type(torch.float)\n",
    "        ids = torch.tensor(ids).type(torch.int)\n",
    "        q_ids = torch.tensor(q_ids).type(torch.int)\n",
    "        return TensorDataset(neg_hs, pos_hs, gt_labels, ids, q_ids)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Check if datasets exists in files and load them otherwise generate:\n",
    "\n",
    "if os.path.exists(f\"data/llama{llama_size}/truthful_qa_one_hs_ds.pt\"):\n",
    "    one_hs_ds = torch.load(f\"data/llama{llama_size}/truthful_qa_one_hs_ds.pt\")\n",
    "else:\n",
    "    one_hs_ds = create_tensordataset(\n",
    "        one_statement_ds_generator, hf_model, tokenizer, max_per_q=EXAMPLES_PER_QUESTION\n",
    "    )\n",
    "    torch.save(one_hs_ds, f\"data/llama{llama_size}/truthful_qa_one_hs_ds.pt\")\n",
    "\n",
    "if os.path.exists(f\"data/llama{llama_size}/truthful_qa_disj_hs_ds.pt\"):\n",
    "    disj_hs_ds = torch.load(f\"data/llama{llama_size}/truthful_qa_disj_hs_ds.pt\")\n",
    "else:\n",
    "    disj_hs_ds = create_tensordataset(\n",
    "        disj_ds_generator, hf_model, tokenizer, max_per_q=EXAMPLES_PER_QUESTION\n",
    "    )\n",
    "    torch.save(disj_hs_ds, f\"data/llama{llama_size}/truthful_qa_disj_hs_ds.pt\")\n",
    "\n",
    "if os.path.exists(f\"data/llama{llama_size}/truthful_qa_conj_hs_ds.pt\"):\n",
    "    conj_hs_ds = torch.load(f\"data/llama{llama_size}/truthful_qa_conj_hs_ds.pt\")\n",
    "else:\n",
    "    conj_hs_ds = create_tensordataset(\n",
    "        conj_ds_generator, hf_model, tokenizer, max_per_q=EXAMPLES_PER_QUESTION\n",
    "    )\n",
    "    torch.save(conj_hs_ds, f\"data/llama{llama_size}/truthful_qa_conj_hs_ds.pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Split to train and test:\n",
    "def split_train_test_ds(ds):\n",
    "    n = len(ds)\n",
    "    TRAIN_RATIO = 0.8\n",
    "    train_n = int(n * TRAIN_RATIO)\n",
    "    train_ds, test_ds = random_split(ds, [train_n, n - train_n])\n",
    "\n",
    "    return DataLoader(train_ds, batch_size=32), DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "\n",
    "one_train_dl, one_test_dl = split_train_test_ds(one_hs_ds)\n",
    "disj_train_dl, disj_test_dl = split_train_test_ds(disj_hs_ds)\n",
    "conj_train_dl, conj_test_dl = split_train_test_ds(conj_hs_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Split to train and test:\n",
    "def split_train_test_ds(ds):\n",
    "    n = len(ds)\n",
    "    TRAIN_RATIO = 0.8\n",
    "    train_n = int(n * TRAIN_RATIO)\n",
    "    train_ds, test_ds = random_split(ds, [train_n, n - train_n])\n",
    "\n",
    "    return DataLoader(train_ds, batch_size=32), DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "\n",
    "one_train_dl, one_test_dl = split_train_test_ds(one_hs_ds)\n",
    "disj_train_dl, disj_test_dl = split_train_test_ds(disj_hs_ds)\n",
    "conj_train_dl, conj_test_dl = split_train_test_ds(conj_hs_ds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "    def __init__(self, input_dim, lr=1e-3, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.input_dim = input_dim\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pos_x, neg_x, y, *_ = batch\n",
    "        x = neg_x - pos_x\n",
    "        y_hat = self.fc(x).squeeze()\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "    def __init__(self, input_dim, lr=1e-3, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.input_dim = input_dim\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pos_x, neg_x, y, *_ = batch\n",
    "        x = neg_x - pos_x\n",
    "        y_hat = self.fc(x).squeeze()\n",
    "        loss = self.loss(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "def calc_LR_accuracy(train_dl, test_dl, report, report_index_name):\n",
    "    LR_probe = LogisticRegression(train_dl.dataset.dataset.tensors[0].shape[1])\n",
    "    trainer = pl.Trainer(max_epochs=50)\n",
    "    trainer.fit(LR_probe, train_dl)\n",
    "    LR_probe.eval()\n",
    "    # Accuracy:\n",
    "    LR_probe = LR_probe.to(device=\"cpu\")\n",
    "    test_neg_x, test_pos_x, test_y, ids, q_ids = (\n",
    "        t.cpu() for t in test_dl.dataset.dataset.tensors\n",
    "    )\n",
    "    test_x = test_pos_x - test_neg_x\n",
    "    y_hat = LR_probe(test_x).squeeze().sigmoid()\n",
    "    y_hat = (y_hat > 0.5).float()\n",
    "    accuracy = (y_hat == test_y).float().mean()\n",
    "    # Get indexes of questions with all correct predictions:\n",
    "    known_questions = set()\n",
    "    for q_id in q_ids.unique():\n",
    "        sample_indexes = (q_ids == q_id).nonzero(as_tuple=False).squeeze()\n",
    "        all_guessed = (y_hat[sample_indexes] == test_y[sample_indexes]).all()\n",
    "        if all_guessed:\n",
    "            known_questions.add(q_id.item())\n",
    "\n",
    "    report.loc[report_index_name, \"LR, acc\"] = accuracy.item()\n",
    "    report.loc[report_index_name, \"LR, # samples\"] = len(test_y)\n",
    "    report.loc[report_index_name, \"LR, # correct\"] = sum(y_hat == test_y).item()\n",
    "    report.loc[report_index_name, \"LR, # known q.\"] = len(known_questions)\n",
    "    report.loc[report_index_name, \"LR, DS true/all\"] = test_y.sum().item() / len(test_y)\n",
    "\n",
    "    return LR_probe, known_questions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def calc_LR_accuracy(train_dl, test_dl, report, report_index_name):\n",
    "    LR_probe = LogisticRegression(train_dl.dataset.dataset.tensors[0].shape[1])\n",
    "    trainer = pl.Trainer(max_epochs=50)\n",
    "    trainer.fit(LR_probe, train_dl)\n",
    "    LR_probe.eval()\n",
    "    # Accuracy:\n",
    "    LR_probe = LR_probe.to(device=\"cpu\")\n",
    "    test_neg_x, test_pos_x, test_y, ids, q_ids = (\n",
    "        t.cpu() for t in test_dl.dataset.dataset.tensors\n",
    "    )\n",
    "    test_x = test_pos_x - test_neg_x\n",
    "    y_hat = LR_probe(test_x).squeeze().sigmoid()\n",
    "    y_hat = (y_hat > 0.5).float()\n",
    "    accuracy = (y_hat == test_y).float().mean()\n",
    "    # Get indexes of questions with all correct predictions:\n",
    "    known_questions = set()\n",
    "    for q_id in q_ids.unique():\n",
    "        sample_indexes = (q_ids == q_id).nonzero(as_tuple=False).squeeze()\n",
    "        all_guessed = (y_hat[sample_indexes] == test_y[sample_indexes]).all()\n",
    "        if all_guessed:\n",
    "            known_questions.add(q_id.item())\n",
    "\n",
    "    report.loc[report_index_name, \"LR, acc\"] = accuracy.item()\n",
    "    report.loc[report_index_name, \"LR, # samples\"] = len(test_y)\n",
    "    report.loc[report_index_name, \"LR, # correct\"] = sum(y_hat == test_y).item()\n",
    "    report.loc[report_index_name, \"LR, # known q.\"] = len(known_questions)\n",
    "    report.loc[report_index_name, \"LR, DS true/all\"] = test_y.sum().item() / len(test_y)\n",
    "\n",
    "    return LR_probe, known_questions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Drop all columns in report that begins with LR:\n",
    "for col in report.columns:\n",
    "    if col.startswith(\"LR\"):\n",
    "        del report[col]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Drop all columns in report that begins with LR:\n",
    "for col in report.columns:\n",
    "    if col.startswith(\"LR\"):\n",
    "        del report[col]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# LR probe - One statement\n",
    "statement_LR_probe, lr_one_indexes = calc_LR_accuracy(\n",
    "    one_train_dl, one_test_dl, report, \"One statement\"\n",
    ")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /workspace/dlkworks/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type              | Params\n",
      "-------------------------------------------\n",
      "0 | fc   | Linear            | 5.1 K \n",
      "1 | loss | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9dac9581098347b2b381353a0095e432"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "\n",
       "               LR, DS true/all  \n",
       "One statement              0.5  "
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# LR probe - One statement\n",
    "statement_LR_probe, lr_one_indexes = calc_LR_accuracy(\n",
    "    one_train_dl, one_test_dl, report, \"One statement\"\n",
    ")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type              | Params\n",
      "-------------------------------------------\n",
      "0 | fc   | Linear            | 5.1 K \n",
      "1 | loss | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "282d6c86eee94cc982b0b3432bd1149a"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "\n",
       "               LR, DS true/all  \n",
       "One statement              0.5  "
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# LR probe - Disjunction statement\n",
    "disj_LR_probe, lr_disj_indexes = calc_LR_accuracy(\n",
    "    disj_train_dl, disj_test_dl, report, \"Disjunction\"\n",
    ")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type              | Params\n",
      "-------------------------------------------\n",
      "0 | fc   | Linear            | 5.1 K \n",
      "1 | loss | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "084d5c6ef97b450ea7f0efe3a0c3a94c"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>0.950346</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "Disjunction    0.950346         1591.0         1512.0           738.0   \n",
       "\n",
       "               LR, DS true/all  \n",
       "One statement         0.500000  \n",
       "Disjunction           0.513514  "
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# LR probe - Conjunction statement\n",
    "conj_LR_probe, lr_conj_indexes = calc_LR_accuracy(\n",
    "    conj_train_dl, conj_test_dl, report, \"Conjunction\"\n",
    ")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type              | Params\n",
      "-------------------------------------------\n",
      "0 | fc   | Linear            | 5.1 K \n",
      "1 | loss | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "986b9309cce94bbaa2d81c179bb5f308"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>0.950346</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>0.958440</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.477621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "Disjunction    0.950346         1591.0         1512.0           738.0   \n",
       "Conjunction    0.958440         1564.0         1499.0           753.0   \n",
       "\n",
       "               LR, DS true/all  \n",
       "One statement         0.500000  \n",
       "Disjunction           0.513514  \n",
       "Conjunction           0.477621  "
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Save probes\n",
    "\n",
    "torch.save(\n",
    "    statement_LR_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_one_LR_probe.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    disj_LR_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_disj_LR_probe.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    conj_LR_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_conj_LR_probe.pt\",\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "class CCS(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, tensor_ds: TensorDataset, lr=1e-3, batch_size=32, var_normalize=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(tensor_ds.tensors[0].shape[1], 1), nn.Sigmoid()\n",
    "        )\n",
    "        self.batch_size = batch_size\n",
    "        self.x_mean = [\n",
    "            tensor_ds.tensors[1].mean(axis=0),  # 0 - neg\n",
    "            tensor_ds.tensors[0].mean(axis=0),  # 1 - pos\n",
    "        ]\n",
    "        self.x_std = [\n",
    "            tensor_ds.tensors[1].std(axis=0),\n",
    "            tensor_ds.tensors[0].std(axis=0),\n",
    "        ]\n",
    "        # self.running_sum = [\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        # ]\n",
    "        # self.running_num = [0, 0]\n",
    "        # self.x_mean = [\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        # ]\n",
    "        # self.x_std = [\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        #    torch.zeros(input_dim, device=device),\n",
    "        # ]\n",
    "        self.known_questions = set()\n",
    "        self.var_normalize = var_normalize\n",
    "        self.Epsilon = 1e-8\n",
    "\n",
    "    def _normalize(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        pn_type: int,  # Positive (1) or negative (0).\n",
    "        update_running=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Mean-normalizes the data x (of shape (n, d))\n",
    "        If self.var_normalize, also divides by the standard deviation\n",
    "        \"\"\"\n",
    "        # if update_running:\n",
    "        #    self.running_sum[pn_type] += x.sum(axis=0)\n",
    "        #    self.running_num[pn_type] += len(x)\n",
    "        # self.x_mean[pn_type] = self.running_sum[pn_type] / self.running_num[pn_type]\n",
    "        # normalized_x = x - self.x_mean[pn_type]\n",
    "        normalized_x = x - x.mean(axis=0)\n",
    "        if self.var_normalize:\n",
    "            normalized_x /= x.std(axis=0) + self.Epsilon\n",
    "            # self.x_std[pn_type] = (x - self.x_mean[pn_type]).pow(2).sum(\n",
    "            #    axis=0\n",
    "            # ) / self.running_num[pn_type]\n",
    "            #normalized_x /= self.x_std[pn_type] + self.Epsilon\n",
    "\n",
    "        return normalized_x\n",
    "\n",
    "    def loss(self, p0: torch.Tensor, p1: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Returns the CCS loss for two probabilities each of shape (n,1) or (n,)\n",
    "        \"\"\"\n",
    "        confidence = (torch.min(p0, p1) ** 2).mean(0)\n",
    "        consistency = ((p0 - (1 - p1)) ** 2).mean(0)\n",
    "        return confidence + consistency\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        neg_x, pos_x, *_ = batch\n",
    "        pos_x = self._normalize(pos_x, pn_type=1)\n",
    "        neg_x = self._normalize(neg_x, pn_type=0)\n",
    "        neg_p = self.fc(neg_x).squeeze()\n",
    "        pos_p = self.fc(pos_x).squeeze()\n",
    "        loss = self.loss(neg_p, pos_p)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        neg_x, pos_x, y, *_ = batch\n",
    "        pos_x = self._normalize(pos_x, pn_type=1)\n",
    "        neg_x = self._normalize(neg_x, pn_type=0)\n",
    "        with torch.no_grad():\n",
    "            neg_p = self.fc(neg_x).squeeze()\n",
    "            pos_p = self.fc(pos_x).squeeze()\n",
    "        avg_confidence = 0.5 * (pos_p + (1 - neg_p))\n",
    "        predictions = (avg_confidence.detach() >= 0.5).int()\n",
    "        acc = (predictions == y).float().mean()\n",
    "        acc = max(acc, 1 - acc)\n",
    "        self.log(\"test_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        # Known questions:\n",
    "        for q_id in batch[4].unique():\n",
    "            q_indexes = (batch[4] == q_id).nonzero(as_tuple=False).squeeze()\n",
    "            if (predictions[q_indexes] == y[q_indexes]).all():\n",
    "                q_id = q_id.item()\n",
    "                self.known_questions.add(q_id)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "best_lr = 0.0001\n",
    "best_bs = 32"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Do sweep:\n",
    "best_acc = None\n",
    "train_dl = conj_train_dl\n",
    "test_dl = conj_test_dl\n",
    "for lr in (1e-2, 1e-3, 1e-4, 3e-4, 7e-4, 1e-5):\n",
    "    for bs in (32, 64, 128):\n",
    "        ccs = CCS(\n",
    "            train_dl.dataset.dataset,\n",
    "            lr=lr,\n",
    "            batch_size=bs,\n",
    "            var_normalize=False,\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=5,\n",
    "            profiler=None,\n",
    "            logger=False,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "        )\n",
    "        trainer.fit(ccs, train_dl)\n",
    "        ccs.eval()\n",
    "\n",
    "        # Accuracy:\n",
    "        trainer.test(ccs, test_dl, verbose=False)\n",
    "        acc = trainer.callback_metrics[\"test_acc\"]\n",
    "        if best_acc is None or acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_lr = lr\n",
    "            best_bs = bs\n",
    "print(f\"Best acc: {best_acc:.4}, lr: {best_lr}, bs: {best_bs}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:653: Checkpoint directory /workspace/dlkworks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "def calc_CCS_accuracy(train_dl, test_dl, report, report_index_name, tries=6, epochs=50):\n",
    "    best_probe = None\n",
    "    best_acc = None\n",
    "    report.loc[report_index_name, \"CCS, random acc\"] = 0.0\n",
    "    r_a_list = []\n",
    "    t_a_list = []\n",
    "    for t in range(tries):\n",
    "        ccs = CCS(\n",
    "            train_dl.dataset.dataset, lr=best_lr, batch_size=best_bs, var_normalize=False\n",
    "        )\n",
    "\n",
    "        # Random accuracy\n",
    "        trainer = pl.Trainer(max_epochs=epochs)   # Avoid overfit?\n",
    "        trainer.test(ccs, test_dl, verbose=False)\n",
    "        trainer.known_questions = set()\n",
    "        r_a_list += [trainer.callback_metrics[ \"test_acc\" ].item()]\n",
    "\n",
    "        # Now train\n",
    "        trainer.fit(ccs, train_dl)\n",
    "        ccs.eval()\n",
    "        # Accuracy:\n",
    "        trainer.test(ccs, test_dl, verbose=False)\n",
    "        test_acc = trainer.callback_metrics[\"test_acc\" ].item()\n",
    "        if best_acc is None or best_acc < test_acc:\n",
    "            best_probe = ccs\n",
    "            best_acc = test_acc\n",
    "        t_a_list += [test_acc]\n",
    "\n",
    "    report.loc[report_index_name, \"CCS, acc, mean\"] = np.array(t_a_list).mean()\n",
    "    report.loc[report_index_name, \"CCS, acc, std\"] = np.array(t_a_list).std()\n",
    "    report.loc[report_index_name, \"CCS, random acc, mean\"] = np.array(r_a_list).mean()\n",
    "    report.loc[report_index_name, \"CCS, random acc, std\"] = np.array(r_a_list).std()\n",
    "\n",
    "    report.loc[report_index_name, \"CCS, # samples\"] = len(\n",
    "        test_dl.dataset.dataset.tensors[2]\n",
    "    )\n",
    "    report.loc[report_index_name, \"CCS, # known q\"] = len(best_probe.known_questions)\n",
    "    report.loc[report_index_name, \"CCS, DS true/all\"] = test_dl.dataset.dataset.tensors[\n",
    "        2\n",
    "    ].sum().item() / len(test_dl.dataset.dataset.tensors[2])\n",
    "\n",
    "    return best_probe"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# CCS probe - One statement\n",
    "one_ccs_probe = calc_CCS_accuracy(one_train_dl, one_test_dl, report, \"One statement\")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f43cd2213e243e4aac4d98efdbdf548"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (41) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f837772db7d34266a4494a562318f745"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab31f4ba833345fc84eed9dae104afbf"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d193aeaa054b4daa8e51d05dc4b17b23"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6acd4f62e6aa47f19ddc5f8f502483fb"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cacadcb302e94fc8a5913c3ab9887447"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79f7cdd3aff64428ac790210c6d6fd11"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0757ea6eee34812ab55f7cf43aa6778"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ff0a354b3dd456b800d140d8e76ad8b"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e9455ac76ed4c90ba5719d6e9cac4e4"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e55b3dc7cde64d5f899af32444b5eb1b"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe7601485215405e99f9bcdee81c285e"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8459be09b63b452eb05307691422a811"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d4f9fa686cb4552a79e6eea554b309f"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "294415e70c914f7fa5efd36ab10e4335"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da01d592c0204b26be6ce9641c73c66b"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9ee6af8a66a452b919521f4d5b6d6b3"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0faf3cf734f48ef87c52162da54df24"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "      <th>CCS, random acc</th>\n",
       "      <th>CCS, acc, mean</th>\n",
       "      <th>CCS, acc, std</th>\n",
       "      <th>CCS, random acc, mean</th>\n",
       "      <th>CCS, random acc, std</th>\n",
       "      <th>CCS, # samples</th>\n",
       "      <th>CCS, # known q</th>\n",
       "      <th>CCS, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702854</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.01807</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>0.950346</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>0.958440</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.477621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "Disjunction    0.950346         1591.0         1512.0           738.0   \n",
       "Conjunction    0.958440         1564.0         1499.0           753.0   \n",
       "\n",
       "               LR, DS true/all  CCS, random acc  CCS, acc, mean  \\\n",
       "One statement         0.500000              0.0        0.702854   \n",
       "Disjunction           0.513514              NaN             NaN   \n",
       "Conjunction           0.477621              NaN             NaN   \n",
       "\n",
       "               CCS, acc, std  CCS, random acc, mean  CCS, random acc, std  \\\n",
       "One statement       0.032528               0.594801               0.01807   \n",
       "Disjunction              NaN                    NaN                   NaN   \n",
       "Conjunction              NaN                    NaN                   NaN   \n",
       "\n",
       "               CCS, # samples  CCS, # known q  CCS, DS true/all  \n",
       "One statement          1634.0           251.0               0.5  \n",
       "Disjunction               NaN             NaN               NaN  \n",
       "Conjunction               NaN             NaN               NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# CCS probe - Disjunction statement\n",
    "disj_ccs_probe = calc_CCS_accuracy(disj_train_dl, disj_test_dl, report, \"Disjunction\")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20b439305515423db1348282291634d5"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b8b2fb313984b66b81e8ec7a0e9503c"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf799967fccf487ebd167b52e3bc517a"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "284e18086af540d3841920a3311f6459"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e649831e7994e7b94f1b412ce7c092a"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a870393ceddf4814a43951ace6110576"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4ad9016114b4327b29fd3862f85b73f"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e24ad2ed3594a3b8828ac020b61c4b4"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34c21d004c90491d99f3a2f12e1addb3"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d98579a7ca5647478c696f489080ce23"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c28a8285d0646ccb2b24b5e78cfa713"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c91a6e921c2c4d9f8cc9147e19394cdd"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1079e8c18e524092855a83efc444fb2a"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fc2636b3436465abeca8cd65f29a4d0"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c96f072d166448dfa26bcec069717fa8"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ec7e9cb68cc4a589d129edabc345ac7"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "001f7519a5d34a3bb7d365fc7f3ec275"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff6011aa4b144a93b0ba2966ac487120"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "      <th>CCS, random acc</th>\n",
       "      <th>CCS, acc, mean</th>\n",
       "      <th>CCS, acc, std</th>\n",
       "      <th>CCS, random acc, mean</th>\n",
       "      <th>CCS, random acc, std</th>\n",
       "      <th>CCS, # samples</th>\n",
       "      <th>CCS, # known q</th>\n",
       "      <th>CCS, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702854</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>0.950346</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588819</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>0.958440</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.477621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "Disjunction    0.950346         1591.0         1512.0           738.0   \n",
       "Conjunction    0.958440         1564.0         1499.0           753.0   \n",
       "\n",
       "               LR, DS true/all  CCS, random acc  CCS, acc, mean  \\\n",
       "One statement         0.500000              0.0        0.702854   \n",
       "Disjunction           0.513514              0.0        0.588819   \n",
       "Conjunction           0.477621              NaN             NaN   \n",
       "\n",
       "               CCS, acc, std  CCS, random acc, mean  CCS, random acc, std  \\\n",
       "One statement       0.032528               0.594801              0.018070   \n",
       "Disjunction         0.025365               0.590909              0.019806   \n",
       "Conjunction              NaN                    NaN                   NaN   \n",
       "\n",
       "               CCS, # samples  CCS, # known q  CCS, DS true/all  \n",
       "One statement          1634.0           251.0          0.500000  \n",
       "Disjunction            1591.0           196.0          0.513514  \n",
       "Conjunction               NaN             NaN               NaN  "
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# CCS probe - Conjunction statement\n",
    "conj_ccs_probe = calc_CCS_accuracy(conj_train_dl, conj_test_dl, report, \"Conjunction\")\n",
    "report"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1073a576612421c84492e3b66651415"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=35` in the `DataLoader` to improve performance.\n",
      "/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (40) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f89237ec026e449fa645e3377575277d"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cf0176360fd47c88bf00139444721d7"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15d21998c4394147ae01d1151e2a0e2a"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a35b74624114c7fb1794b62885142af"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f0a1481b3f04e5d9c5ae2d915c7a03c"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1ec32334a4b45bab8c4c85f4f4613e3"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ade8406d16e4c44af67fa7cad3b1201"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f27a66628e764f1cb9330c84a3d3693c"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c7553ca5d074bd4beca106bcebcaac0"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "380700e71fcf415ab2a2348d30d3a831"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ae67d3d92df46e5953dd5681b394ee2"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d136256e65a74cab99c5d6b7be785b23"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d89cc7a1fe45ed8d9bfb42d5f5f08a"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e53b162424247599a6a05258c351c6f"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b08a3f44d59347ad8dfa8abc1d154c05"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | fc   | Sequential | 5.1 K \n",
      "------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8f111142e0448ff82106d2a6db7a490"
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18d22a2b8e2f4b088e24b94b2ad9ec3a"
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR, acc</th>\n",
       "      <th>LR, # samples</th>\n",
       "      <th>LR, # correct</th>\n",
       "      <th>LR, # known q.</th>\n",
       "      <th>LR, DS true/all</th>\n",
       "      <th>CCS, random acc</th>\n",
       "      <th>CCS, acc, mean</th>\n",
       "      <th>CCS, acc, std</th>\n",
       "      <th>CCS, random acc, mean</th>\n",
       "      <th>CCS, random acc, std</th>\n",
       "      <th>CCS, # samples</th>\n",
       "      <th>CCS, # known q</th>\n",
       "      <th>CCS, DS true/all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>0.958384</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702854</td>\n",
       "      <td>0.032528</td>\n",
       "      <td>0.594801</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>1634.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>0.950346</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588819</td>\n",
       "      <td>0.025365</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.019806</td>\n",
       "      <td>1591.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>0.958440</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1499.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>0.477621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683706</td>\n",
       "      <td>0.069655</td>\n",
       "      <td>0.620873</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.477621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                LR, acc  LR, # samples  LR, # correct  LR, # known q.  \\\n",
       "One statement  0.958384         1634.0         1566.0           751.0   \n",
       "Disjunction    0.950346         1591.0         1512.0           738.0   \n",
       "Conjunction    0.958440         1564.0         1499.0           753.0   \n",
       "\n",
       "               LR, DS true/all  CCS, random acc  CCS, acc, mean  \\\n",
       "One statement         0.500000              0.0        0.702854   \n",
       "Disjunction           0.513514              0.0        0.588819   \n",
       "Conjunction           0.477621              0.0        0.683706   \n",
       "\n",
       "               CCS, acc, std  CCS, random acc, mean  CCS, random acc, std  \\\n",
       "One statement       0.032528               0.594801              0.018070   \n",
       "Disjunction         0.025365               0.590909              0.019806   \n",
       "Conjunction         0.069655               0.620873              0.036830   \n",
       "\n",
       "               CCS, # samples  CCS, # known q  CCS, DS true/all  \n",
       "One statement          1634.0           251.0          0.500000  \n",
       "Disjunction            1591.0           196.0          0.513514  \n",
       "Conjunction            1564.0           237.0          0.477621  "
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Intersection matrix:\n",
    "\n",
    "def intersection(a, b):\n",
    "    im = np.zeros((3, 3))\n",
    "    for i, a_set in enumerate(a):\n",
    "        for j, b_set in enumerate(b):\n",
    "            im[i, j] = len(a_set.intersection(b_set))\n",
    "    return im\n",
    "\n",
    "fs_sets = [fs_one_known_qs, fs_disj_known_qs, fs_conj_known_qs]\n",
    "ccs_sets = [one_ccs_probe.known_questions, disj_ccs_probe.known_questions, conj_ccs_probe.known_questions]\n",
    "lr_sets = [lr_one_indexes, lr_disj_indexes, lr_conj_indexes]\n",
    "sets_names = [\"FS\", \"CCS\", \"LR\"]\n",
    "subsets_names = [\"One statement\", \"Disjunction\", \"Conjunction\"]\n",
    "for i, sets in enumerate([fs_sets, ccs_sets, lr_sets]):\n",
    "    for j, sets2 in enumerate([fs_sets, ccs_sets, lr_sets][i+1:]):\n",
    "        j = j + i + 1\n",
    "        print(f\"Intersection {sets_names[i]} vs {sets_names[j]}:\")\n",
    "        df = pd.DataFrame(\n",
    "                intersection(sets, sets2),\n",
    "                columns=subsets_names,\n",
    "                index=subsets_names,\n",
    "            )\n",
    "        display(df)\n",
    "        np.save(f\"data/llama{llama_size}/truthful_qa_{sets_names[i]}_vs_{sets_names[j]}.npy\", df.to_numpy())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One statement</th>\n",
       "      <th>Disjunction</th>\n",
       "      <th>Conjunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>91.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               One statement  Disjunction  Conjunction\n",
       "One statement           91.0         54.0         98.0\n",
       "Disjunction             30.0         22.0         29.0\n",
       "Conjunction             30.0         20.0         34.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One statement</th>\n",
       "      <th>Disjunction</th>\n",
       "      <th>Conjunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>267.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               One statement  Disjunction  Conjunction\n",
       "One statement          267.0        270.0        262.0\n",
       "Disjunction             85.0         85.0         80.0\n",
       "Conjunction             74.0         69.0         73.0"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>One statement</th>\n",
       "      <th>Disjunction</th>\n",
       "      <th>Conjunction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>One statement</th>\n",
       "      <td>210.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disjunction</th>\n",
       "      <td>183.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conjunction</th>\n",
       "      <td>218.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               One statement  Disjunction  Conjunction\n",
       "One statement          210.0        231.0        242.0\n",
       "Disjunction            183.0        155.0        181.0\n",
       "Conjunction            218.0        209.0        200.0"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "ccs_all_qs = set.union(*ccs_sets)\n",
    "fs_all_qs = set.union(*fs_sets)\n",
    "lr_all_qs = set.union(*lr_sets)\n",
    "\n",
    "# Questions identified by CCS but not by LR or by FS:\n",
    "ccs_only_qs = ccs_all_qs - fs_all_qs - lr_all_qs\n",
    "# Questions identified by LR but not by CCS or by FS:\n",
    "lr_only_qs = lr_all_qs - fs_all_qs - ccs_all_qs\n",
    "# Questions identified by FS but not by CCS or by LR:\n",
    "fs_only_qs = fs_all_qs - ccs_all_qs - lr_all_qs\n",
    "\n",
    "# Display:\n",
    "print(\"Unique questions identified by CCS but not by LR or by FS:\")\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"CCS only\": len(ccs_only_qs),\n",
    "        \"LR only\": len(lr_only_qs),\n",
    "        \"FS only\": len(fs_only_qs),\n",
    "        \"CCS and LR\": len(ccs_all_qs & lr_all_qs),\n",
    "        \"CCS and FS\": len(ccs_all_qs & fs_all_qs),\n",
    "        \"LR and FS\": len(lr_all_qs & fs_all_qs),\n",
    "        \"CCS and LR and FS\": len(ccs_all_qs & lr_all_qs & fs_all_qs),\n",
    "    },\n",
    "    index=[\"# questions\"],\n",
    ").T\n",
    "\n",
    "display(df)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CCS only</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR only</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FS only</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCS and LR</th>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCS and FS</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR and FS</th>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCS and LR and FS</th>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   # questions\n",
       "CCS only                     1\n",
       "LR only                    176\n",
       "FS only                      0\n",
       "CCS and LR                 510\n",
       "CCS and FS                 233\n",
       "LR and FS                  363\n",
       "CCS and LR and FS          233"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Save probes:\n",
    "torch.save(\n",
    "    one_ccs_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_one_ccs_probe.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    disj_ccs_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_disj_ccs_probe.pt\",\n",
    ")\n",
    "torch.save(\n",
    "    conj_ccs_probe.state_dict(),\n",
    "    f\"data/llama{llama_size}/truthful_qa_conj_ccs_probe.pt\",\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# Save known questions:\n",
    "with open(f\"data/llama{llama_size}/known_questions.npy\", \"wb\") as f:\n",
    "    np.save(f, fs_one_known_qs)\n",
    "    np.save(f, fs_disj_known_qs)\n",
    "    np.save(f, fs_conj_known_qs)\n",
    "    np.save(f, lr_one_indexes)\n",
    "    np.save(f, lr_disj_indexes)\n",
    "    np.save(f, lr_conj_indexes)\n",
    "    np.save(f, list(one_ccs_probe.known_questions))\n",
    "    np.save(f, list(disj_ccs_probe.known_questions))\n",
    "    np.save(f, list(conj_ccs_probe.known_questions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Save report\n",
    "\n",
    "report.to_csv(f\"data/llama{llama_size}/truthful_qa_report_data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Create bar plot with accuracies for Few shot, LR, CCS as bars\n",
    "# and Random (mean) as a line:\n",
    "\n",
    "# Multiply all accuracy by 100 and round by 1:\n",
    "freport = (report * 100).round(1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=freport.index,\n",
    "        y=freport[\"FS, acc\"],\n",
    "        name=\"FS\",\n",
    "        marker_color=\"rgb(55, 83, 109)\",\n",
    "        text=freport[\"FS, acc\"],\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=freport.index,\n",
    "        y=freport[\"LR, acc\"],\n",
    "        name=\"LR\",\n",
    "        marker_color=\"rgb(26, 118, 255)\",\n",
    "        text=freport[\"LR, acc\"],\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=freport.index,\n",
    "        y=freport[\"CCS, acc\"],\n",
    "        name=\"CCS\",\n",
    "        marker_color=\"rgb(255, 118, 26)\",\n",
    "        text=freport[\"CCS, acc\"],\n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=freport.index,\n",
    "        y=freport[\"CCS, random acc\"],\n",
    "        name=\"Random (mean)\",\n",
    "        marker_color=\"rgb(255, 118, 26)\",\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Accuracy on TruthfulQA dataset in %\",\n",
    "    xaxis_title=\"Sentence type\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    legend_title=\"Model\",\n",
    "    template=pt_template,\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'FS, acc'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FS, acc'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m/workspace/dlkworks/accuracy.py:11\u001b[0m\n\u001b[1;32m      6\u001b[0m freport \u001b[39m=\u001b[39m (report \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m)\u001b[39m.\u001b[39mround(\u001b[39m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m fig \u001b[39m=\u001b[39m go\u001b[39m.\u001b[39mFigure()\n\u001b[1;32m      8\u001b[0m fig\u001b[39m.\u001b[39madd_trace(\n\u001b[1;32m      9\u001b[0m     go\u001b[39m.\u001b[39mBar(\n\u001b[1;32m     10\u001b[0m         x\u001b[39m=\u001b[39mfreport\u001b[39m.\u001b[39mindex,\n\u001b[0;32m---> 11\u001b[0m         y\u001b[39m=\u001b[39mfreport[\u001b[39m\"\u001b[39;49m\u001b[39mFS, acc\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     12\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFS\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         marker_color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrgb(55, 83, 109)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         text\u001b[39m=\u001b[39mfreport[\u001b[39m\"\u001b[39m\u001b[39mFS, acc\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m fig\u001b[39m.\u001b[39madd_trace(\n\u001b[1;32m     18\u001b[0m     go\u001b[39m.\u001b[39mBar(\n\u001b[1;32m     19\u001b[0m         x\u001b[39m=\u001b[39mfreport\u001b[39m.\u001b[39mindex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m fig\u001b[39m.\u001b[39madd_trace(\n\u001b[1;32m     27\u001b[0m     go\u001b[39m.\u001b[39mBar(\n\u001b[1;32m     28\u001b[0m         x\u001b[39m=\u001b[39mfreport\u001b[39m.\u001b[39mindex,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FS, acc'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save fig:\n",
    "fig.write_image(f\"data/llama{llama_size}/truthful_qa_report.png\")\n",
    "freport.to_csv(f\"data/llama{llama_size}/truthful_qa_report.csv\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display random as mean ± std:\n",
    "\n",
    "print(\"Table\")\n",
    "freport = report.copy()\n",
    "freport.rename(\n",
    "    columns={\n",
    "        \"FS, acc\": f\"FS, accuracy\",\n",
    "        \"LR, acc\": f\"LR, accuracy\",\n",
    "        \"CCS, acc\": f\"CCS, accuracy\",\n",
    "        \"CCS, random acc\": f\"Random, accuracy\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convert columns with 'accuracy' word into percentage:\n",
    "for col in freport.columns:\n",
    "    if \"accuracy\" in col:\n",
    "        freport[col] = (freport[col] * 100).round(1)\n",
    "# Convert columns with '#' char into integer:\n",
    "for col in freport.columns:\n",
    "    if \"#\" in col:\n",
    "        freport[col] = freport[col].astype(int)\n",
    "\n",
    "\n",
    "freport.to_csv(f\"data/llama{llama_size}/truthful_qa_report_styled.csv\")\n",
    "display(freport)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "",
     "evalue": "",
     "traceback": [
      "\u001b[1;31mCell was canceled due to an error in a previous cell."
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}