{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from IPython.display import display\n",
    "from collections import namedtuple\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from jaxtyping import Int, Float\n",
    "from jinja2 import Environment, PackageLoader, select_autoescape\n",
    "from pathlib import Path\n",
    "from pprint import pp\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from utils.truthful_qa_ds import get_question_answer_dataset\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "\n",
    "login()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pp(device)\n",
    "np_rand = np.random.default_rng(seed=100500)\n",
    "model_type = torch.float16"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0f242acb9ba4fd2b0bb9f25171f3f96"
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device(type='cuda')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load model\n",
    "# llama_path = \"../llama/7bf_converted/\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=model_type,\n",
    "    device_map=device,\n",
    ")\n",
    "model.eval()\n",
    "pp(model)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1aeeff28e39749d581ff7e3df935d057"
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f76dd9ef91442ffadc11ccabd9d6106"
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92ce4983d76941bfbcbc4d5c5abd3fae"
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7bfa230788d4166934e9295adcc1fee"
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55ed9e03bd4b4e39a5b60731705ebbdd"
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5afca7835df474ba989774211ed9c9a"
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d782f320e6574246a861a18cb122563b"
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d9c822d57224c1aae8d5db702aefe4e"
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b25fd4fd4b848c68e88f4fd2684d844"
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97349f58901a46b3962e60c1965e0d7c"
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3859da657e3478fb67ebcffdb1cffc6"
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "true_token = tokenizer.encode(\"True\")[1]\n",
    "false_token = tokenizer.encode(\"False\")[1]\n",
    "print(true_token)\n",
    "print(false_token)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5852\n",
      "7700\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "truthfulqa = load_dataset(\"truthful_qa\", \"generation\")  # 817 rows\n",
    "env = Environment(loader=PackageLoader(\"utils\"), autoescape=select_autoescape())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3d825a5714d4eca8f798a038925d27e"
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02db462771b2494ca5fe1eeb4d9b1651"
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b41c5505c21443d98123375c181df73"
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87955dd03d0845ba947cc26faf048c8a"
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/99.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "909e55c8a9a54244ba5291f56de1cad8"
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/817 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Accuracy on the TruthfulQA dataset, few shot:\n",
    "count = 0\n",
    "correct_samples = []\n",
    "correct_n = 0\n",
    "qa_t = env.get_template(\"question_answer.jinja\")\n",
    "with torch.no_grad():\n",
    "    p_bar = tqdm(list(enumerate(truthfulqa[\"validation\"])))\n",
    "    for i, row in p_bar:\n",
    "        def is_correct_answer(take_correct):\n",
    "            input_ = qa_t.render(\n",
    "                row,\n",
    "                is_correct_answer=take_correct\n",
    "            ),\n",
    "            t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "            t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "            outputs = model(**t_output, output_hidden_states=False)\n",
    "            pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "            predicted = (pred[true_token] > pred[false_token]).item()\n",
    "            return predicted == take_correct\n",
    "        with_true = is_correct_answer(True)\n",
    "        count += 1\n",
    "        if with_true:\n",
    "            correct_n += 1\n",
    "        with_false = is_correct_answer(False)\n",
    "        count += 1\n",
    "        if with_false:\n",
    "            correct_n += 1\n",
    "        if with_true and with_false:\n",
    "            correct_samples.append(row)\n",
    "        p_bar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, both {len(correct_samples)}\"\n",
    "        )\n",
    "# Result: Correct 972, count 1634, accuracy 0.5949, both 261"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Correct 969, count 1634, accuracy 0.593, both 259: 100%|██████████| 817/817 [01:53<00:00,  7.21it/s] \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Accuracy on the TruthfulQA dataset, few shot:\n",
    "count = 0\n",
    "correct_samples = []\n",
    "correct_n = 0\n",
    "qa_t = env.get_template(\"question_answer.jinja\")\n",
    "with torch.no_grad():\n",
    "    p_bar = tqdm(list(enumerate(truthfulqa[\"validation\"])))\n",
    "    for i, row in p_bar:\n",
    "        def is_correct_answer(take_correct):\n",
    "            input_ = qa_t.render(\n",
    "                row,\n",
    "                is_correct_answer=take_correct\n",
    "            ),\n",
    "            t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "            t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "            outputs = model(**t_output, output_hidden_states=False)\n",
    "            pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "            predicted = (pred[true_token] > pred[false_token]).item()\n",
    "            return predicted == take_correct\n",
    "        with_true = is_correct_answer(True)\n",
    "        count += 1\n",
    "        if with_true:\n",
    "            correct_n += 1\n",
    "        with_false = is_correct_answer(False)\n",
    "        count += 1\n",
    "        if with_false:\n",
    "            correct_n += 1\n",
    "        if with_true and with_false:\n",
    "            correct_samples.append(row)\n",
    "        p_bar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, both {len(correct_samples)}\"\n",
    "        )\n",
    "# Result: Correct 972, count 1634, accuracy 0.5949, both 261"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Correct 950, count 1634, accuracy 0.5814, both 242: 100%|██████████| 817/817 [02:03<00:00,  6.62it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Now calculate accuracy for compound sentences for correctly \n",
    "# detected samples. Expectation: should guess all correctly.\n",
    "\n",
    "count = 0\n",
    "correct_compound = []\n",
    "correct_n = 0\n",
    "qas_t = env.get_template(\"question_answers.jinja\")\n",
    "with torch.no_grad():\n",
    "    p_bar = tqdm(list(enumerate(correct_samples)))\n",
    "    for i, row in p_bar:\n",
    "        def is_correct_answer(take_correct):\n",
    "            input_ = qas_t.render(\n",
    "                row,\n",
    "                is_correct_answer=take_correct,\n",
    "                is_disjunction=False,\n",
    "            ),\n",
    "            t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "            t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "            outputs = model(**t_output, output_hidden_states=False)\n",
    "            pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "            predicted = (pred[true_token] > pred[false_token]).item()\n",
    "            return predicted == take_correct\n",
    "        with_true = is_correct_answer(True)\n",
    "        count += 1\n",
    "        if with_true:\n",
    "            correct_n += 1\n",
    "        with_false = is_correct_answer(False)\n",
    "        count += 1\n",
    "        if with_false:\n",
    "            correct_n += 1\n",
    "        if with_true and with_false:\n",
    "            correct_compound.append(row)\n",
    "        p_bar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, both {len(correct_compound)}\"\n",
    "        )\n",
    "\n",
    "# Random? Correct 289, count 522, accuracy 0.5536, both 48: 100%|██████████| 261/261 [00:44<00:00,  5.84it/s]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Correct 261, count 484, accuracy 0.5393, both 37: 100%|██████████| 242/242 [00:53<00:00,  4.49it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Accuracy on the TruthfulQA dataset, few shot:\n",
    "count = 0\n",
    "correct_samples = []\n",
    "correct_n = 0\n",
    "qa_t = env.get_template(\"question_answer.jinja\")\n",
    "with torch.no_grad():\n",
    "    p_bar = tqdm(list(enumerate(truthfulqa[\"validation\"])))\n",
    "    for i, row in p_bar:\n",
    "        def is_correct_answer(take_correct):\n",
    "            input_ = qa_t.render(\n",
    "                row,\n",
    "                is_correct_answer=take_correct\n",
    "            ),\n",
    "            t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "            t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "            outputs = model(**t_output, output_hidden_states=False)\n",
    "            pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "            predicted = (pred[true_token] > pred[false_token]).item()\n",
    "            return predicted == take_correct\n",
    "        with_true = is_correct_answer(True)\n",
    "        count += 1\n",
    "        if with_true:\n",
    "            correct_n += 1\n",
    "        with_false = is_correct_answer(False)\n",
    "        count += 1\n",
    "        if with_false:\n",
    "            correct_n += 1\n",
    "        if with_true and with_false:\n",
    "            correct_samples.append(row)\n",
    "        p_bar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, both {len(correct_samples)}\"\n",
    "        )\n",
    "# Result: Correct 972, count 1634, accuracy 0.5949, both 261"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Correct 969, count 1634, accuracy 0.593, both 259: 100%|██████████| 817/817 [01:53<00:00,  7.22it/s] \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Now calculate accuracy for compound sentences for correctly \n",
    "# detected samples. Expectation: should guess all correctly.\n",
    "\n",
    "count = 0\n",
    "correct_compound = []\n",
    "correct_n = 0\n",
    "qas_t = env.get_template(\"question_answers.jinja\")\n",
    "with torch.no_grad():\n",
    "    p_bar = tqdm(list(enumerate(correct_samples)))\n",
    "    for i, row in p_bar:\n",
    "        def is_correct_answer(take_correct):\n",
    "            input_ = qas_t.render(\n",
    "                row,\n",
    "                is_correct_answer=take_correct,\n",
    "                is_disjunction=False,\n",
    "            ),\n",
    "            t_output = tokenizer(input_, return_tensors=\"pt\")\n",
    "            t_output = {k: t_output[k].to(device) for k in t_output}\n",
    "            outputs = model(**t_output, output_hidden_states=False)\n",
    "            pred = outputs.logits[0, -1].softmax(dim=-1)\n",
    "            predicted = (pred[true_token] > pred[false_token]).item()\n",
    "            return predicted == take_correct\n",
    "        with_true = is_correct_answer(True)\n",
    "        count += 1\n",
    "        if with_true:\n",
    "            correct_n += 1\n",
    "        with_false = is_correct_answer(False)\n",
    "        count += 1\n",
    "        if with_false:\n",
    "            correct_n += 1\n",
    "        if with_true and with_false:\n",
    "            correct_compound.append(row)\n",
    "        p_bar.set_description(\n",
    "            f\"Correct {correct_n}, count {count}, accuracy {correct_n / count:.4}, both {len(correct_compound)}\"\n",
    "        )\n",
    "\n",
    "# Random? Correct 289, count 522, accuracy 0.5536, both 48: 100%|██████████| 261/261 [00:44<00:00,  5.84it/s]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Correct 287, count 518, accuracy 0.5541, both 48: 100%|██████████| 259/259 [00:55<00:00,  4.64it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Previous 2 accuracy cells without: \"Answer these questions:\". It is 1.8 percent higher\n",
    "# "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}